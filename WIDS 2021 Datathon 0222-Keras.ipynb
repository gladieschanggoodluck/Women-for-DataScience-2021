{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import HTML\n",
    "#https://stackoverflow.com/questions/27934885/how-to-hide-code-from-cells-in-ipython-notebook-visualized-with-nbviewer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<script>\n",
       "code_show=true; \n",
       "function code_toggle() {\n",
       " if (code_show){\n",
       " $('div.input').hide();\n",
       " } else {\n",
       " $('div.input').show();\n",
       " }\n",
       " code_show = !code_show\n",
       "} \n",
       "$( document ).ready(code_toggle);\n",
       "</script>\n",
       "\n",
       "<style>\n",
       ".output_png {\n",
       "    display: table-cell;\n",
       "    text-align: center;\n",
       "    vertical-align: middle;\n",
       "}\n",
       "</style>\n",
       "<form action=\"javascript:code_toggle()\"><input type=\"submit\" value=\"Click here to toggle on/off the code.\"></form>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "HTML('''<script>\n",
    "code_show=true; \n",
    "function code_toggle() {\n",
    " if (code_show){\n",
    " $('div.input').hide();\n",
    " } else {\n",
    " $('div.input').show();\n",
    " }\n",
    " code_show = !code_show\n",
    "} \n",
    "$( document ).ready(code_toggle);\n",
    "</script>\n",
    "\n",
    "<style>\n",
    ".output_png {\n",
    "    display: table-cell;\n",
    "    text-align: center;\n",
    "    vertical-align: middle;\n",
    "}\n",
    "</style>\n",
    "<form action=\"javascript:code_toggle()\"><input type=\"submit\" value=\"Click here to toggle on/off the code.\"></form>''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "## import libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from matplotlib import pyplot as plt\n",
    "import xgboost as xgb\n",
    "import missingno as msno\n",
    "from numpy import isnan\n",
    "from sklearn.metrics import accuracy_score,make_scorer\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV , RandomizedSearchCV, cross_val_score\n",
    "from sklearn.metrics import roc_auc_score, classification_report,accuracy_score, confusion_matrix, roc_curve, auc, f1_score\n",
    "from sklearn.impute import SimpleImputer\n",
    "from numpy import nan\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import MinMaxScaler,StandardScaler\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn import linear_model\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "from sklearn.inspection import permutation_importance\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "sns.set() # will create pretty matplots\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "%matplotlib inline\n",
    "#global format settigns for plots\n",
    "plt.rcParams['font.sans-serif'] = 'Arial'\n",
    "plt.rcParams['font.family'] = 'sans-serif'\n",
    "plt.rcParams['text.color'] = '#000000'\n",
    "plt.rcParams['axes.labelcolor']= '#000000'\n",
    "plt.rcParams['xtick.color'] = '#000000'\n",
    "plt.rcParams['ytick.color'] = '#000000'\n",
    "plt.rcParams['font.size']=12\n",
    "warnings.filterwarnings('ignore')\n",
    "pd.set_option('precision', 3) # number precision for pandas\n",
    "pd.set_option('display.max_rows', 12)\n",
    "pd.set_option('display.float_format', '{:20,.3f}'.format) # get rid of scientific notation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Functions used later\n",
    "\n",
    "## identify categorical columns\n",
    "# https://pbpython.com/categorical-encoding.html\n",
    "def identifyCatVar(df):\n",
    "    cat_df = df.select_dtypes(include = ['object']).copy()\n",
    "    cat_df.head()\n",
    "    return cat_df\n",
    "\n",
    "#Function to summarize the number of rows with missing values for each column\n",
    "\n",
    "def summarizeMissing(df):\n",
    "    missing_df = []\n",
    "    columns=['Variable','Missing','Percent']\n",
    "    for i in range(df.shape[1]):\n",
    "        # count number of rows with missing values\n",
    "        n_miss = df.iloc[:,i].isnull().sum()\n",
    "        perc = n_miss / df.shape[0] * 100\n",
    "        values = [i,n_miss,perc]\n",
    "        zipped = zip(columns, values)\n",
    "        dict_miss = dict(zipped)\n",
    "        missing_df.append(dict_miss)\n",
    "    return missing_df\n",
    "#Function to replace NAN values with mode value\n",
    "def impute_nan_most_frequent_category(DataFrame,ColName):\n",
    "    # .mode()[0] - gives first category name\n",
    "     most_frequent_category=DataFrame[ColName].mode()[0]\n",
    "    # replace nan values with most occured category\n",
    "     DataFrame[ColName].fillna(most_frequent_category,inplace=True)\n",
    "\n",
    "\n",
    "#https://stackoverflow.com/questions/56088264/trouble-training-xgboost-on-categorical-column\n",
    "#Function to convert categories to strings so that XGBClassfier works\n",
    "def catToString(X):\n",
    "    df = identifyCatVar(X)\n",
    "    lbl = preprocessing.LabelEncoder()\n",
    "    for i in df.columns:\n",
    "        X[i] = lbl.fit_transform(X[i].astype(str))\n",
    "    return X\n",
    "\n",
    "def callROC_Curve(y_pred_prob,y_train):\n",
    "    # keep probabilities for the positive outcome only\n",
    "    y_pred_prob = y_pred_prob[:,1]\n",
    "    fpr, tpr, thresholds = roc_curve(y_train, y_pred_prob)\n",
    "    best_thresh = getoptimalThreshold(fpr,tpr,thresholds,y_pred_prob,y_train)\n",
    "    plt.show()\n",
    "    return best_thresh\n",
    "\n",
    "def exploreConfusionMatrix(y_pred,y_pred_prob,y,threshold):\n",
    "    threshold = float(threshold)\n",
    "    #y_pred = fit.predict_proba(X)\n",
    "    # keep probabilities for the positive outcome only\n",
    "    y_pred_prob = y_pred_prob[:,1]\n",
    "    pred = [ 0 if x < threshold else 1 for x in y_pred_prob]\n",
    "    print(\"\\nConfusion Matrix for Threshold=%.3f\" %threshold+\"\\n\")\n",
    "    metrics = getClassificationMetrics(y_pred,y_pred_prob,y,threshold)\n",
    "    return pd.DataFrame(metrics)\n",
    "\n",
    "# apply threshold to positive probabilities to create labels\n",
    "def to_labels(pos_probs, threshold):\n",
    "\treturn (pos_probs > threshold).astype('int')\n",
    "\n",
    "#computes optimal threshold based on f1 score. Called from CallROC_Curve\n",
    "def getoptimalThreshold(fpr, tpr,thresholds, probs,y_train):\n",
    "    #the function creates a f1 score for the data using al lthe thresholds\n",
    "    scores_t = [f1_score(y_train, to_labels(probs, t)) for t in thresholds]\n",
    "    # get index of best threshold with max score\n",
    "    ix = np.argmax(scores_t)\n",
    "    print('\\nBest Threshold=%.3f, F-Score=%.3f' % (thresholds[ix], scores_t[ix]))\n",
    "    #sets limits for axis\n",
    "    plt.plot([0,1], [0,1], linestyle='--', label='No Skill')\n",
    "    #plot the fpr and tpr for the model\n",
    "    plt.plot(fpr, tpr, marker='.', label='Model')\n",
    "    #plot the best threshold point\n",
    "    plt.scatter(fpr[ix], tpr[ix], marker='D', color='black', label='Best')\n",
    "    #set labels and legend\n",
    "    plt.xlabel('False Positive Rate (1-Specificity)')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('Receiver Operating Characteristic (ROC) Curve')\n",
    "    plt.legend()\n",
    "    #return the best threshold based on the f1score\n",
    "    return thresholds[ix]\n",
    "\n",
    "#Mainly used to fill the final table of metrics exactly as asked and plot the confusion matrix(cm) where required\n",
    "#takes the best estimator and any x and y values alogn with a threshold to compute the metrics and cm. used in exploreConfusionMatrix function\n",
    "def getClassificationMetrics(y_pred, pred_prob, y_test,threshold):\n",
    "    #compute predicted probabilities\n",
    "    #pred_prob = fit.predict_proba(X)\n",
    "    #keep probabilities for the positive outcome only\n",
    "    #pred_prob = pred_prob[:,1]\n",
    "    CM = confusion_matrix(y_test,y_pred)\n",
    "    TN = CM[0][0]; FN = CM[1][0] ; TP = CM[1][1]; FP = CM[0][1]\n",
    "    Population = TN+FN+TP+FP\n",
    "    Accuracy   = round( ((TP+TN)*100) / Population,2)\n",
    "    Accuracy = str(Accuracy)+'%'\n",
    "    Recall     = round( TP / (TP+FN),4 )\n",
    "    FPR        = round( FP / (TN+FP),4 )\n",
    "    Specificity = 1-FPR\n",
    "    FDR        = round( FP / (TP+FP),4 )\n",
    "    Precision  = round( TP / (TP+FP),4 )\n",
    "    auc = roc_auc_score(y_test, pred_prob)\n",
    "    plt.title('Confusion Matrix')\n",
    "    #get values from the confusion matrix inbuilt function and use it in a seaborn plot to make it look pretty\n",
    "    sns.heatmap( pd.DataFrame(CM, columns=['Predicted Negative', 'Predicted Positive'], index=['Negative', 'Positive']), annot=True, cmap='Blues',fmt=\"\")\n",
    "    plt.show()\n",
    "    #store metrics in a data frame and return. This format will eb useful to plot the final table\n",
    "    metrics = pd.DataFrame({\n",
    "        'Metrics':['Accuracy','AUC','Threshold','Recall','Specificity','FDR', 'Precision'],'Value':[Accuracy,auc,threshold,Recall,Specificity,FDR, Precision]})\n",
    "    metrics = metrics.set_index('Metrics')\n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read Dataset and Clean Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read the training data set\n",
    "df = pd.read_csv(\"TrainingWiDS2021.csv\") \n",
    "#drop the duplicate index column\n",
    "df = df.drop(columns=df.columns[0]) # removing unnamed column index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Variable</th>\n",
       "      <th>Missing</th>\n",
       "      <th>Percent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>4988</td>\n",
       "      <td>3.832</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>4490</td>\n",
       "      <td>3.450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175</th>\n",
       "      <td>175</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>176</th>\n",
       "      <td>176</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>177</th>\n",
       "      <td>177</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>178</th>\n",
       "      <td>178</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>179</th>\n",
       "      <td>179</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>180 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Variable  Missing              Percent\n",
       "0           0        0                0.000\n",
       "1           1        0                0.000\n",
       "2           2     4988                3.832\n",
       "3           3     4490                3.450\n",
       "4           4        0                0.000\n",
       "..        ...      ...                  ...\n",
       "175       175        0                0.000\n",
       "176       176        0                0.000\n",
       "177       177        0                0.000\n",
       "178       178        0                0.000\n",
       "179       179        0                0.000\n",
       "\n",
       "[180 rows x 3 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#print missing value summary\n",
    "pd.DataFrame(summarizeMissing(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop columns with > 80% missing values\n",
    "pct_null = df.isnull().sum() / len(df)\n",
    "missing_features = pct_null[pct_null > 0.80].index\n",
    "df.drop(missing_features, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(130157, 148)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Variable</th>\n",
       "      <th>Missing</th>\n",
       "      <th>Percent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>4988</td>\n",
       "      <td>3.832</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>4490</td>\n",
       "      <td>3.450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143</th>\n",
       "      <td>143</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144</th>\n",
       "      <td>144</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>145</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>146</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>147</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>148 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Variable  Missing              Percent\n",
       "0           0        0                0.000\n",
       "1           1        0                0.000\n",
       "2           2     4988                3.832\n",
       "3           3     4490                3.450\n",
       "4           4        0                0.000\n",
       "..        ...      ...                  ...\n",
       "143       143        0                0.000\n",
       "144       144        0                0.000\n",
       "145       145        0                0.000\n",
       "146       146        0                0.000\n",
       "147       147        0                0.000\n",
       "\n",
       "[148 rows x 3 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#checkshape of new dataframe after dropping columns with >80% missing values\n",
    "print(df.shape)\n",
    "pd.DataFrame(summarizeMissing(df))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Impute missing categorical values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a copy of the dataframe to impute dategorical columns missing values\n",
    "cat_impute_df = identifyCatVar(df)\n",
    "#Call function to impute with most occured category\n",
    "for Columns in cat_impute_df.columns.to_list():\n",
    "    impute_nan_most_frequent_category(cat_impute_df,Columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop the categorical columsn to impute numericalvalues\n",
    "num_impute_df= df.drop(columns=cat_impute_df.columns.to_list())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Impute missing numerical values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' Optional\\n#Better way to impute numerical values but takes a very long tiem for a large dataset\\n#https://towardsdatascience.com/preprocessing-regression-imputation-of-missing-continuous-values-f612179bafb4\\n#https://towardsdatascience.com/3-underrated-strategies-to-deal-with-missing-values-a539fb6c0690\\nimputer = IterativeImputer(ExtraTreesRegressor(),random_state=13)\\nvalues = cat_impute_df.values\\nimpute_data = pd.DataFrame(imputer.fit_transform(values))\\n# count the number of NaN values in each column\\nsummarizeMissing(impute_data)\\n'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "''' Optional\n",
    "#Better way to impute numerical values but takes a very long tiem for a large dataset\n",
    "#https://towardsdatascience.com/preprocessing-regression-imputation-of-missing-continuous-values-f612179bafb4\n",
    "#https://towardsdatascience.com/3-underrated-strategies-to-deal-with-missing-values-a539fb6c0690\n",
    "imputer = IterativeImputer(ExtraTreesRegressor(),random_state=13)\n",
    "values = cat_impute_df.values\n",
    "impute_data = pd.DataFrame(imputer.fit_transform(values))\n",
    "# count the number of NaN values in each column\n",
    "summarizeMissing(impute_data)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Variable</th>\n",
       "      <th>Missing</th>\n",
       "      <th>Percent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137</th>\n",
       "      <td>137</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138</th>\n",
       "      <td>138</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139</th>\n",
       "      <td>139</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140</th>\n",
       "      <td>140</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141</th>\n",
       "      <td>141</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>142 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Variable  Missing              Percent\n",
       "0           0        0                0.000\n",
       "1           1        0                0.000\n",
       "2           2        0                0.000\n",
       "3           3        0                0.000\n",
       "4           4        0                0.000\n",
       "..        ...      ...                  ...\n",
       "137       137        0                0.000\n",
       "138       138        0                0.000\n",
       "139       139        0                0.000\n",
       "140       140        0                0.000\n",
       "141       141        0                0.000\n",
       "\n",
       "[142 rows x 3 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#another imputing technicque based on mean, median, most_frequent \n",
    "#all vlaues give same results. therefore going with most_frequent\n",
    "imputer_s = SimpleImputer(missing_values=nan, strategy='most_frequent')\n",
    "# transform the dataset\n",
    "impute_data = pd.DataFrame(imputer_s.fit_transform(num_impute_df))\n",
    "# count the number of NaN values in each column\n",
    "pd.DataFrame(summarizeMissing(impute_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merge back final imputed dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(130157, 148)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#create new dataframe with imputed data and combine with categorical variables to create final imputed dataset\n",
    "impute_data.columns = num_impute_df.columns\n",
    "final_data = pd.concat([impute_data,cat_impute_df],axis=1)\n",
    "final_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>encounter_id</th>\n",
       "      <th>hospital_id</th>\n",
       "      <th>age</th>\n",
       "      <th>bmi</th>\n",
       "      <th>elective_surgery</th>\n",
       "      <th>height</th>\n",
       "      <th>icu_id</th>\n",
       "      <th>pre_icu_los_days</th>\n",
       "      <th>readmission_status</th>\n",
       "      <th>weight</th>\n",
       "      <th>...</th>\n",
       "      <th>leukemia</th>\n",
       "      <th>lymphoma</th>\n",
       "      <th>solid_tumor_with_metastasis</th>\n",
       "      <th>diabetes_mellitus</th>\n",
       "      <th>ethnicity</th>\n",
       "      <th>gender</th>\n",
       "      <th>hospital_admit_source</th>\n",
       "      <th>icu_admit_source</th>\n",
       "      <th>icu_stay_type</th>\n",
       "      <th>icu_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>214,826.000</td>\n",
       "      <td>118.000</td>\n",
       "      <td>68.000</td>\n",
       "      <td>22.733</td>\n",
       "      <td>0.000</td>\n",
       "      <td>180.300</td>\n",
       "      <td>92.000</td>\n",
       "      <td>0.542</td>\n",
       "      <td>0.000</td>\n",
       "      <td>73.900</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>Caucasian</td>\n",
       "      <td>M</td>\n",
       "      <td>Floor</td>\n",
       "      <td>Floor</td>\n",
       "      <td>admit</td>\n",
       "      <td>CTICU</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>246,060.000</td>\n",
       "      <td>81.000</td>\n",
       "      <td>77.000</td>\n",
       "      <td>27.422</td>\n",
       "      <td>0.000</td>\n",
       "      <td>160.000</td>\n",
       "      <td>90.000</td>\n",
       "      <td>0.928</td>\n",
       "      <td>0.000</td>\n",
       "      <td>70.200</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>Caucasian</td>\n",
       "      <td>F</td>\n",
       "      <td>Floor</td>\n",
       "      <td>Floor</td>\n",
       "      <td>admit</td>\n",
       "      <td>Med-Surg ICU</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>276,985.000</td>\n",
       "      <td>118.000</td>\n",
       "      <td>25.000</td>\n",
       "      <td>31.953</td>\n",
       "      <td>0.000</td>\n",
       "      <td>172.700</td>\n",
       "      <td>93.000</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.000</td>\n",
       "      <td>95.300</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>Caucasian</td>\n",
       "      <td>F</td>\n",
       "      <td>Emergency Department</td>\n",
       "      <td>Accident &amp; Emergency</td>\n",
       "      <td>admit</td>\n",
       "      <td>Med-Surg ICU</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>262,220.000</td>\n",
       "      <td>118.000</td>\n",
       "      <td>81.000</td>\n",
       "      <td>22.636</td>\n",
       "      <td>1.000</td>\n",
       "      <td>165.100</td>\n",
       "      <td>92.000</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.000</td>\n",
       "      <td>61.700</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>Caucasian</td>\n",
       "      <td>F</td>\n",
       "      <td>Operating Room</td>\n",
       "      <td>Operating Room / Recovery</td>\n",
       "      <td>admit</td>\n",
       "      <td>CTICU</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>201,746.000</td>\n",
       "      <td>33.000</td>\n",
       "      <td>19.000</td>\n",
       "      <td>67.815</td>\n",
       "      <td>0.000</td>\n",
       "      <td>188.000</td>\n",
       "      <td>91.000</td>\n",
       "      <td>0.074</td>\n",
       "      <td>0.000</td>\n",
       "      <td>68.000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>Caucasian</td>\n",
       "      <td>M</td>\n",
       "      <td>Emergency Department</td>\n",
       "      <td>Accident &amp; Emergency</td>\n",
       "      <td>admit</td>\n",
       "      <td>Med-Surg ICU</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 148 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          encounter_id          hospital_id                  age  \\\n",
       "0          214,826.000              118.000               68.000   \n",
       "1          246,060.000               81.000               77.000   \n",
       "2          276,985.000              118.000               25.000   \n",
       "3          262,220.000              118.000               81.000   \n",
       "4          201,746.000               33.000               19.000   \n",
       "\n",
       "                   bmi     elective_surgery               height  \\\n",
       "0               22.733                0.000              180.300   \n",
       "1               27.422                0.000              160.000   \n",
       "2               31.953                0.000              172.700   \n",
       "3               22.636                1.000              165.100   \n",
       "4               67.815                0.000              188.000   \n",
       "\n",
       "                icu_id     pre_icu_los_days   readmission_status  \\\n",
       "0               92.000                0.542                0.000   \n",
       "1               90.000                0.928                0.000   \n",
       "2               93.000                0.001                0.000   \n",
       "3               92.000                0.001                0.000   \n",
       "4               91.000                0.074                0.000   \n",
       "\n",
       "                weight  ...             leukemia             lymphoma  \\\n",
       "0               73.900  ...                0.000                0.000   \n",
       "1               70.200  ...                0.000                0.000   \n",
       "2               95.300  ...                0.000                0.000   \n",
       "3               61.700  ...                0.000                0.000   \n",
       "4               68.000  ...                0.000                0.000   \n",
       "\n",
       "   solid_tumor_with_metastasis    diabetes_mellitus  ethnicity  gender  \\\n",
       "0                        0.000                1.000  Caucasian       M   \n",
       "1                        0.000                1.000  Caucasian       F   \n",
       "2                        0.000                0.000  Caucasian       F   \n",
       "3                        0.000                0.000  Caucasian       F   \n",
       "4                        0.000                0.000  Caucasian       M   \n",
       "\n",
       "   hospital_admit_source           icu_admit_source  icu_stay_type  \\\n",
       "0                  Floor                      Floor          admit   \n",
       "1                  Floor                      Floor          admit   \n",
       "2   Emergency Department       Accident & Emergency          admit   \n",
       "3         Operating Room  Operating Room / Recovery          admit   \n",
       "4   Emergency Department       Accident & Emergency          admit   \n",
       "\n",
       "       icu_type  \n",
       "0         CTICU  \n",
       "1  Med-Surg ICU  \n",
       "2  Med-Surg ICU  \n",
       "3         CTICU  \n",
       "4  Med-Surg ICU  \n",
       "\n",
       "[5 rows x 148 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#make sure final_dataset looks good\n",
    "final_data.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create dependent and undependent variables to run classification witht train and test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 288x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#https://www.kaggle.com/celniker/wids2021-initial-eda-and-tuned-lgbm-0-86293\n",
    "#Checking proportion of data\n",
    "fig, ax =plt.subplots(1,2)\n",
    "plt.figure(figsize=(4,4))                                                \n",
    "sns.countplot('diabetes_mellitus',data=final_data,ax=ax[0])\n",
    "final_data['diabetes_mellitus'].value_counts().plot.pie(explode=[0,0.2],autopct='%1.2f%%',ax=ax[1])\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create X and Y from final dataset\n",
    "#https://www.kdnuggets.com/2017/03/simple-xgboost-tutorial-iris-dataset.html\n",
    "#convert categorical data to strings\n",
    "final_data = catToString(final_data,)\n",
    "\n",
    "#create X and Y\n",
    "X = final_data.drop(final_data[['diabetes_mellitus']],axis=1)\n",
    "Y = final_data[['diabetes_mellitus']]\n",
    "#create train and test set to check accuracy, using stratify as the data is imbalanced\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, train_size=0.70,stratify=Y,random_state=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression to compare with XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of logistic regression classifier on test set: 80.78%\n"
     ]
    }
   ],
   "source": [
    "## Logistic Regression with cross validation\n",
    "# we must apply the scaling to the test set that we computed for the training set\n",
    "clf_lr = linear_model.LogisticRegressionCV(cv=5, random_state=1).fit(X_train, y_train)\n",
    "y_pred = clf_lr.predict(X_test)\n",
    "print('Accuracy of logistic regression classifier on test set: %.2f%%' %(clf_lr.score(X_test, y_test)*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM to compare with XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_model = SVC()\n",
    "svm_model.fit(X_train, y_train.values.ravel())\n",
    "# make predictions for test data and evaluate\n",
    "svm_pred = svm_model.predict(X_test)\n",
    "accuracy_svm = accuracy_score(y_test, svm_pred)\n",
    "print(\"\\n\\nAccuracy with 147 features: %.2f%%\" % (accuracy * 100.0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Accuracy with 147 features: 83.67%\n"
     ]
    }
   ],
   "source": [
    "#https://machinelearningmastery.com/feature-importance-and-feature-selection-with-xgboost-in-python/\n",
    "# fit model on all the training data and check accuracy\n",
    "model_fs = xgb.XGBClassifier(verbosity=0)\n",
    "model_fs.fit(X_train, y_train);\n",
    "# make predictions for test data and evaluate\n",
    "pred_fs = model_fs.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, pred_fs)\n",
    "print(\"\\n\\nAccuracy with 147 features: %.2f%%\" % (accuracy * 100.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://mljar.com/blog/feature-importance-xgboost/\n",
    "##Feature Selection using XGB\n",
    "#create a subset of data removing thsoe features with importance 0\n",
    "sorted_idx = model_fs.feature_importances_.argsort()\n",
    "feature_imp = pd.DataFrame(X.columns[sorted_idx], model_fs.feature_importances_[sorted_idx])\n",
    "feature_imp = feature_imp.reset_index()\n",
    "feature_imp.columns=['importance','features']\n",
    "reduced_data = final_data[feature_imp[feature_imp[\"importance\"] > 0].features.values.tolist()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Top 10 features\n",
    "feature_imp= feature_imp.set_index('features')\n",
    "feature_imp.tail(10).plot.barh(title='Top 10 Features');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#change categorical variables to strings in the reduced dataset\n",
    "reduced_data = catToString(reduced_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Accuracy with 139 features: 83.67%\n"
     ]
    }
   ],
   "source": [
    "#create new training and test data with reduced data and check accuracy\n",
    "X_train_rd, X_test_rd, y_train, y_test = train_test_split(reduced_data, Y, train_size=0.70,stratify=Y,random_state=1)\n",
    "model_rd = xgb.XGBClassifier(verbosity=0)\n",
    "model_rd.fit(X_train_rd, y_train)\n",
    "# make predictions for test data and evaluate\n",
    "pred_rd = model_rd.predict(X_test_rd)\n",
    "accuracy_rd = accuracy_score(y_test, pred_rd)\n",
    "print(\"\\n\\nAccuracy with 139 features: %.2f%%\" % (accuracy_rd * 100.0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyper parameter thning for XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Takes forever to run so skip if you don't have tiem to run this and just see the results\n",
    "#https://medium.com/@juniormiranda_23768/ensemble-methods-tuning-a-xgboost-model-with-scikit-learn-54ff669f988a\n",
    "#Perform hyperparameter tunign on reduced data to save time\n",
    "# Define our search space for grid search\n",
    "#peforming on 3 splits in interest of time\n",
    "kfold = StratifiedKFold(n_splits=3, random_state=1,shuffle=True)\n",
    "# Create a pipeline\n",
    "pipe = Pipeline([\n",
    "('scaler', StandardScaler()),\n",
    "  ('clf', xgb.XGBClassifier(objective='binary:logistic',verbosity=0))\n",
    "])\n",
    "search_space = [\n",
    "  {\n",
    "    'clf__n_estimators': [150,200],\n",
    "    'clf__learning_rate': [0.01, 0.1, 0.2, 0.3],\n",
    "    'clf__max_depth': range(3, 10),\n",
    "    'clf__colsample_bytree': [i/10.0 for i in range(1, 3)],\n",
    "    'clf__gamma': [i/10.0 for i in range(3)]\n",
    "  }\n",
    "]\n",
    "# AUC and accuracy as score\n",
    "scoring = {'AUC':'roc_auc', 'Accuracy':make_scorer(accuracy_score)}\n",
    "# Define grid search\n",
    "grid = GridSearchCV(\n",
    "  pipe,\n",
    "  param_grid=search_space,\n",
    "  cv=kfold,\n",
    "  scoring=scoring,\n",
    "  refit='AUC'\n",
    ")\n",
    "# Fit grid search\n",
    "model = grid.fit(X_train_rd, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ROC and AUC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#predict using the best model\n",
    "#focusing on accuracy and default threshold\n",
    "print('Best Params: ', model.best_params_)\n",
    "##ROC Curve\n",
    "#find best threshold to use on test dataset\n",
    "#finding threshold on training data takes a long time\n",
    "predict = model.predict(X_test_rd)\n",
    "y_pred_tr = model.predict_proba(X_train_rd)\n",
    "thresh = callROC_Curve(y_pred_tr,y_train)\n",
    "#use threshold now on test set to get metrics\n",
    "y_pred_prob_test = model.predict_proba(X_test_rd)\n",
    "exploreConfusionMatrix(predict, y_pred_prob_test,y_test,thresh)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Applying the best model to the hold out dataset for submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#applying model to hold out data\n",
    "HO = pd.read_csv('UnlabeledWiDS2021.csv')\n",
    "HO = HO.drop(columns=HO.columns[0]) # removing unnamed column index\n",
    "# keep columns in train\n",
    "X_HO = HO[reduced_data.columns]\n",
    "#convert categories to strings\n",
    "X_HO = catToString(X_HO)\n",
    "#we do not know y_HO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>leukemia</th>\n",
       "      <th>h1_temp_min</th>\n",
       "      <th>hepatic_failure</th>\n",
       "      <th>d1_inr_min</th>\n",
       "      <th>h1_sodium_min</th>\n",
       "      <th>immunosuppression</th>\n",
       "      <th>d1_albumin_max</th>\n",
       "      <th>d1_calcium_max</th>\n",
       "      <th>h1_hemaglobin_max</th>\n",
       "      <th>h1_mbp_min</th>\n",
       "      <th>...</th>\n",
       "      <th>d1_glucose_min</th>\n",
       "      <th>age</th>\n",
       "      <th>d1_lactate_max</th>\n",
       "      <th>bmi</th>\n",
       "      <th>icu_id</th>\n",
       "      <th>gcs_verbal_apache</th>\n",
       "      <th>gcs_motor_apache</th>\n",
       "      <th>arf_apache</th>\n",
       "      <th>ventilated_apache</th>\n",
       "      <th>d1_glucose_max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>36.400</td>\n",
       "      <td>0</td>\n",
       "      <td>nan</td>\n",
       "      <td>132.000</td>\n",
       "      <td>0</td>\n",
       "      <td>2.800</td>\n",
       "      <td>9.800</td>\n",
       "      <td>14.500</td>\n",
       "      <td>80.000</td>\n",
       "      <td>...</td>\n",
       "      <td>97.000</td>\n",
       "      <td>72</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>82</td>\n",
       "      <td>5.000</td>\n",
       "      <td>6.000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>104.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>36.700</td>\n",
       "      <td>0</td>\n",
       "      <td>2.200</td>\n",
       "      <td>nan</td>\n",
       "      <td>0</td>\n",
       "      <td>nan</td>\n",
       "      <td>8.500</td>\n",
       "      <td>nan</td>\n",
       "      <td>94.000</td>\n",
       "      <td>...</td>\n",
       "      <td>73.000</td>\n",
       "      <td>86</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>82</td>\n",
       "      <td>5.000</td>\n",
       "      <td>6.000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>102.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>36.400</td>\n",
       "      <td>0</td>\n",
       "      <td>2.400</td>\n",
       "      <td>141.000</td>\n",
       "      <td>0</td>\n",
       "      <td>3.700</td>\n",
       "      <td>9.100</td>\n",
       "      <td>11.800</td>\n",
       "      <td>117.000</td>\n",
       "      <td>...</td>\n",
       "      <td>84.000</td>\n",
       "      <td>72</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>82</td>\n",
       "      <td>5.000</td>\n",
       "      <td>6.000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>141.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>37.000</td>\n",
       "      <td>0</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>0</td>\n",
       "      <td>2.000</td>\n",
       "      <td>9.000</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>...</td>\n",
       "      <td>84.000</td>\n",
       "      <td>66</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>82</td>\n",
       "      <td>4.000</td>\n",
       "      <td>6.000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>84.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>36.600</td>\n",
       "      <td>0</td>\n",
       "      <td>1.100</td>\n",
       "      <td>133.000</td>\n",
       "      <td>0</td>\n",
       "      <td>3.400</td>\n",
       "      <td>8.800</td>\n",
       "      <td>10.700</td>\n",
       "      <td>89.000</td>\n",
       "      <td>...</td>\n",
       "      <td>99.000</td>\n",
       "      <td>89</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>82</td>\n",
       "      <td>5.000</td>\n",
       "      <td>6.000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>159.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10229</th>\n",
       "      <td>0</td>\n",
       "      <td>36.500</td>\n",
       "      <td>0</td>\n",
       "      <td>1.070</td>\n",
       "      <td>nan</td>\n",
       "      <td>0</td>\n",
       "      <td>nan</td>\n",
       "      <td>8.300</td>\n",
       "      <td>9.800</td>\n",
       "      <td>96.000</td>\n",
       "      <td>...</td>\n",
       "      <td>96.000</td>\n",
       "      <td>36</td>\n",
       "      <td>nan</td>\n",
       "      <td>37.500</td>\n",
       "      <td>1108</td>\n",
       "      <td>5.000</td>\n",
       "      <td>6.000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>96.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10230</th>\n",
       "      <td>0</td>\n",
       "      <td>nan</td>\n",
       "      <td>0</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>0</td>\n",
       "      <td>nan</td>\n",
       "      <td>7.900</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>...</td>\n",
       "      <td>94.000</td>\n",
       "      <td>61</td>\n",
       "      <td>nan</td>\n",
       "      <td>32.100</td>\n",
       "      <td>1108</td>\n",
       "      <td>5.000</td>\n",
       "      <td>6.000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>94.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10231</th>\n",
       "      <td>0</td>\n",
       "      <td>nan</td>\n",
       "      <td>0</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>0</td>\n",
       "      <td>nan</td>\n",
       "      <td>7.400</td>\n",
       "      <td>nan</td>\n",
       "      <td>73.000</td>\n",
       "      <td>...</td>\n",
       "      <td>150.000</td>\n",
       "      <td>74</td>\n",
       "      <td>nan</td>\n",
       "      <td>22.700</td>\n",
       "      <td>1108</td>\n",
       "      <td>5.000</td>\n",
       "      <td>6.000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>150.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10232</th>\n",
       "      <td>0</td>\n",
       "      <td>36.100</td>\n",
       "      <td>0</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>0</td>\n",
       "      <td>nan</td>\n",
       "      <td>8.600</td>\n",
       "      <td>nan</td>\n",
       "      <td>89.000</td>\n",
       "      <td>...</td>\n",
       "      <td>98.000</td>\n",
       "      <td>90</td>\n",
       "      <td>nan</td>\n",
       "      <td>19.900</td>\n",
       "      <td>1108</td>\n",
       "      <td>4.000</td>\n",
       "      <td>6.000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>98.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10233</th>\n",
       "      <td>0</td>\n",
       "      <td>37.100</td>\n",
       "      <td>0</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>0</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>88.000</td>\n",
       "      <td>...</td>\n",
       "      <td>nan</td>\n",
       "      <td>30</td>\n",
       "      <td>nan</td>\n",
       "      <td>25.600</td>\n",
       "      <td>1108</td>\n",
       "      <td>1.000</td>\n",
       "      <td>5.000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>nan</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10234 rows × 139 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       leukemia          h1_temp_min  hepatic_failure           d1_inr_min  \\\n",
       "0             0               36.400                0                  nan   \n",
       "1             0               36.700                0                2.200   \n",
       "2             0               36.400                0                2.400   \n",
       "3             0               37.000                0                  nan   \n",
       "4             0               36.600                0                1.100   \n",
       "...         ...                  ...              ...                  ...   \n",
       "10229         0               36.500                0                1.070   \n",
       "10230         0                  nan                0                  nan   \n",
       "10231         0                  nan                0                  nan   \n",
       "10232         0               36.100                0                  nan   \n",
       "10233         0               37.100                0                  nan   \n",
       "\n",
       "             h1_sodium_min  immunosuppression       d1_albumin_max  \\\n",
       "0                  132.000                  0                2.800   \n",
       "1                      nan                  0                  nan   \n",
       "2                  141.000                  0                3.700   \n",
       "3                      nan                  0                2.000   \n",
       "4                  133.000                  0                3.400   \n",
       "...                    ...                ...                  ...   \n",
       "10229                  nan                  0                  nan   \n",
       "10230                  nan                  0                  nan   \n",
       "10231                  nan                  0                  nan   \n",
       "10232                  nan                  0                  nan   \n",
       "10233                  nan                  0                  nan   \n",
       "\n",
       "            d1_calcium_max    h1_hemaglobin_max           h1_mbp_min  ...  \\\n",
       "0                    9.800               14.500               80.000  ...   \n",
       "1                    8.500                  nan               94.000  ...   \n",
       "2                    9.100               11.800              117.000  ...   \n",
       "3                    9.000                  nan                  nan  ...   \n",
       "4                    8.800               10.700               89.000  ...   \n",
       "...                    ...                  ...                  ...  ...   \n",
       "10229                8.300                9.800               96.000  ...   \n",
       "10230                7.900                  nan                  nan  ...   \n",
       "10231                7.400                  nan               73.000  ...   \n",
       "10232                8.600                  nan               89.000  ...   \n",
       "10233                  nan                  nan               88.000  ...   \n",
       "\n",
       "            d1_glucose_min  age       d1_lactate_max                  bmi  \\\n",
       "0                   97.000   72                  nan                  nan   \n",
       "1                   73.000   86                  nan                  nan   \n",
       "2                   84.000   72                  nan                  nan   \n",
       "3                   84.000   66                  nan                  nan   \n",
       "4                   99.000   89                  nan                  nan   \n",
       "...                    ...  ...                  ...                  ...   \n",
       "10229               96.000   36                  nan               37.500   \n",
       "10230               94.000   61                  nan               32.100   \n",
       "10231              150.000   74                  nan               22.700   \n",
       "10232               98.000   90                  nan               19.900   \n",
       "10233                  nan   30                  nan               25.600   \n",
       "\n",
       "       icu_id    gcs_verbal_apache     gcs_motor_apache  arf_apache  \\\n",
       "0          82                5.000                6.000           0   \n",
       "1          82                5.000                6.000           0   \n",
       "2          82                5.000                6.000           0   \n",
       "3          82                4.000                6.000           0   \n",
       "4          82                5.000                6.000           0   \n",
       "...       ...                  ...                  ...         ...   \n",
       "10229    1108                5.000                6.000           0   \n",
       "10230    1108                5.000                6.000           0   \n",
       "10231    1108                5.000                6.000           0   \n",
       "10232    1108                4.000                6.000           0   \n",
       "10233    1108                1.000                5.000           0   \n",
       "\n",
       "       ventilated_apache       d1_glucose_max  \n",
       "0                      0              104.000  \n",
       "1                      0              102.000  \n",
       "2                      0              141.000  \n",
       "3                      1               84.000  \n",
       "4                      0              159.000  \n",
       "...                  ...                  ...  \n",
       "10229                  0               96.000  \n",
       "10230                  0               94.000  \n",
       "10231                  0              150.000  \n",
       "10232                  0               98.000  \n",
       "10233                  0                  nan  \n",
       "\n",
       "[10234 rows x 139 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_HO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#predict probabilities on submission hold out data\n",
    "predict_HO = model_rd.predict_proba(X_HO)\n",
    "submission_df = pd.DataFrame(predict_HO[:,1].round(3),HO.encounter_id)\n",
    "submission_df = submission_df.sort_values('encounter_id')\n",
    "submission_df.columns=['diabetes_mellitus']\n",
    "#submission_df = submission_df.reset_index()\n",
    "#create submission csv\n",
    "submission_df.to_csv(\"wids2021_choksi_huilin_leonard_narayan_0226XG.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>diabetes_mellitus</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>encounter_id</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>135000</th>\n",
       "      <td>0.005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135001</th>\n",
       "      <td>0.013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135002</th>\n",
       "      <td>0.071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135003</th>\n",
       "      <td>0.204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135004</th>\n",
       "      <td>0.022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145996</th>\n",
       "      <td>0.565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145997</th>\n",
       "      <td>0.235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145998</th>\n",
       "      <td>0.343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145999</th>\n",
       "      <td>0.268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146000</th>\n",
       "      <td>0.321</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10234 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                diabetes_mellitus\n",
       "encounter_id                     \n",
       "135000                      0.005\n",
       "135001                      0.013\n",
       "135002                      0.071\n",
       "135003                      0.204\n",
       "135004                      0.022\n",
       "...                           ...\n",
       "145996                      0.565\n",
       "145997                      0.235\n",
       "145998                      0.343\n",
       "145999                      0.268\n",
       "146000                      0.321\n",
       "\n",
       "[10234 rows x 1 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean missing data of hold-out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#applying model to hold out data\n",
    "HO_s = pd.read_csv('UnlabeledWiDS2021.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Impute missing categorical values\n",
    "#create a copy of the dataframe to impute dategorical columns missing values\n",
    "cat_impute_df = identifyCatVar(HO_s)\n",
    "#Call function to impute with most occured category\n",
    "for Columns in cat_impute_df.columns.to_list():\n",
    "    impute_nan_most_frequent_category(cat_impute_df,Columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop the categorical columsn to impute numericalvalues\n",
    "num_impute_df= HO_s.drop(columns=cat_impute_df.columns.to_list())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Impute missing numerical values\n",
    "imputer_s = SimpleImputer(missing_values=nan, strategy='most_frequent')\n",
    "# transform the dataset\n",
    "impute_data = pd.DataFrame(imputer_s.fit_transform(num_impute_df))\n",
    "# count the number of NaN values in each column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10234, 180)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## merge back to the final dataset\n",
    "#create new dataframe with imputed data and combine with categorical variables to create final imputed dataset\n",
    "impute_data.columns = num_impute_df.columns\n",
    "final_data = pd.concat([impute_data,cat_impute_df],axis=1)\n",
    "final_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "## keep columns for prediction\n",
    "HO = final_data.drop(columns=final_data.columns[0]) # removing unnamed column index\n",
    "# keep columns in train\n",
    "X_HO = HO[reduced_data.columns]\n",
    "#convert categories to strings\n",
    "X_HO = catToString(X_HO)\n",
    "#we do not know y_HO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>leukemia</th>\n",
       "      <th>h1_temp_min</th>\n",
       "      <th>hepatic_failure</th>\n",
       "      <th>d1_inr_min</th>\n",
       "      <th>h1_sodium_min</th>\n",
       "      <th>immunosuppression</th>\n",
       "      <th>d1_albumin_max</th>\n",
       "      <th>d1_calcium_max</th>\n",
       "      <th>h1_hemaglobin_max</th>\n",
       "      <th>h1_mbp_min</th>\n",
       "      <th>...</th>\n",
       "      <th>d1_glucose_min</th>\n",
       "      <th>age</th>\n",
       "      <th>d1_lactate_max</th>\n",
       "      <th>bmi</th>\n",
       "      <th>icu_id</th>\n",
       "      <th>gcs_verbal_apache</th>\n",
       "      <th>gcs_motor_apache</th>\n",
       "      <th>arf_apache</th>\n",
       "      <th>ventilated_apache</th>\n",
       "      <th>d1_glucose_max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000</td>\n",
       "      <td>36.400</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.100</td>\n",
       "      <td>132.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>2.800</td>\n",
       "      <td>9.800</td>\n",
       "      <td>14.500</td>\n",
       "      <td>80.000</td>\n",
       "      <td>...</td>\n",
       "      <td>97.000</td>\n",
       "      <td>72.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>26.600</td>\n",
       "      <td>82.000</td>\n",
       "      <td>5.000</td>\n",
       "      <td>6.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>104.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000</td>\n",
       "      <td>36.700</td>\n",
       "      <td>0.000</td>\n",
       "      <td>2.200</td>\n",
       "      <td>138.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>3.100</td>\n",
       "      <td>8.500</td>\n",
       "      <td>10.900</td>\n",
       "      <td>94.000</td>\n",
       "      <td>...</td>\n",
       "      <td>73.000</td>\n",
       "      <td>86.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>26.600</td>\n",
       "      <td>82.000</td>\n",
       "      <td>5.000</td>\n",
       "      <td>6.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>102.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000</td>\n",
       "      <td>36.400</td>\n",
       "      <td>0.000</td>\n",
       "      <td>2.400</td>\n",
       "      <td>141.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>3.700</td>\n",
       "      <td>9.100</td>\n",
       "      <td>11.800</td>\n",
       "      <td>117.000</td>\n",
       "      <td>...</td>\n",
       "      <td>84.000</td>\n",
       "      <td>72.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>26.600</td>\n",
       "      <td>82.000</td>\n",
       "      <td>5.000</td>\n",
       "      <td>6.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>141.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000</td>\n",
       "      <td>37.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.100</td>\n",
       "      <td>138.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>2.000</td>\n",
       "      <td>9.000</td>\n",
       "      <td>10.900</td>\n",
       "      <td>74.000</td>\n",
       "      <td>...</td>\n",
       "      <td>84.000</td>\n",
       "      <td>66.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>26.600</td>\n",
       "      <td>82.000</td>\n",
       "      <td>4.000</td>\n",
       "      <td>6.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>84.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000</td>\n",
       "      <td>36.600</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.100</td>\n",
       "      <td>133.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>3.400</td>\n",
       "      <td>8.800</td>\n",
       "      <td>10.700</td>\n",
       "      <td>89.000</td>\n",
       "      <td>...</td>\n",
       "      <td>99.000</td>\n",
       "      <td>89.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>26.600</td>\n",
       "      <td>82.000</td>\n",
       "      <td>5.000</td>\n",
       "      <td>6.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>159.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10229</th>\n",
       "      <td>0.000</td>\n",
       "      <td>36.500</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.070</td>\n",
       "      <td>138.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>3.100</td>\n",
       "      <td>8.300</td>\n",
       "      <td>9.800</td>\n",
       "      <td>96.000</td>\n",
       "      <td>...</td>\n",
       "      <td>96.000</td>\n",
       "      <td>36.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>37.500</td>\n",
       "      <td>1,108.000</td>\n",
       "      <td>5.000</td>\n",
       "      <td>6.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>96.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10230</th>\n",
       "      <td>0.000</td>\n",
       "      <td>36.700</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.100</td>\n",
       "      <td>138.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>3.100</td>\n",
       "      <td>7.900</td>\n",
       "      <td>10.900</td>\n",
       "      <td>74.000</td>\n",
       "      <td>...</td>\n",
       "      <td>94.000</td>\n",
       "      <td>61.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>32.100</td>\n",
       "      <td>1,108.000</td>\n",
       "      <td>5.000</td>\n",
       "      <td>6.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>94.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10231</th>\n",
       "      <td>0.000</td>\n",
       "      <td>36.700</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.100</td>\n",
       "      <td>138.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>3.100</td>\n",
       "      <td>7.400</td>\n",
       "      <td>10.900</td>\n",
       "      <td>73.000</td>\n",
       "      <td>...</td>\n",
       "      <td>150.000</td>\n",
       "      <td>74.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>22.700</td>\n",
       "      <td>1,108.000</td>\n",
       "      <td>5.000</td>\n",
       "      <td>6.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>150.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10232</th>\n",
       "      <td>0.000</td>\n",
       "      <td>36.100</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.100</td>\n",
       "      <td>138.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>3.100</td>\n",
       "      <td>8.600</td>\n",
       "      <td>10.900</td>\n",
       "      <td>89.000</td>\n",
       "      <td>...</td>\n",
       "      <td>98.000</td>\n",
       "      <td>90.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>19.900</td>\n",
       "      <td>1,108.000</td>\n",
       "      <td>4.000</td>\n",
       "      <td>6.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>98.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10233</th>\n",
       "      <td>0.000</td>\n",
       "      <td>37.100</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.100</td>\n",
       "      <td>138.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>3.100</td>\n",
       "      <td>8.300</td>\n",
       "      <td>10.900</td>\n",
       "      <td>88.000</td>\n",
       "      <td>...</td>\n",
       "      <td>99.000</td>\n",
       "      <td>30.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>25.600</td>\n",
       "      <td>1,108.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>5.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>111.000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10234 rows × 139 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  leukemia          h1_temp_min      hepatic_failure  \\\n",
       "0                    0.000               36.400                0.000   \n",
       "1                    0.000               36.700                0.000   \n",
       "2                    0.000               36.400                0.000   \n",
       "3                    0.000               37.000                0.000   \n",
       "4                    0.000               36.600                0.000   \n",
       "...                    ...                  ...                  ...   \n",
       "10229                0.000               36.500                0.000   \n",
       "10230                0.000               36.700                0.000   \n",
       "10231                0.000               36.700                0.000   \n",
       "10232                0.000               36.100                0.000   \n",
       "10233                0.000               37.100                0.000   \n",
       "\n",
       "                d1_inr_min        h1_sodium_min    immunosuppression  \\\n",
       "0                    1.100              132.000                0.000   \n",
       "1                    2.200              138.000                0.000   \n",
       "2                    2.400              141.000                0.000   \n",
       "3                    1.100              138.000                0.000   \n",
       "4                    1.100              133.000                0.000   \n",
       "...                    ...                  ...                  ...   \n",
       "10229                1.070              138.000                0.000   \n",
       "10230                1.100              138.000                0.000   \n",
       "10231                1.100              138.000                0.000   \n",
       "10232                1.100              138.000                0.000   \n",
       "10233                1.100              138.000                0.000   \n",
       "\n",
       "            d1_albumin_max       d1_calcium_max    h1_hemaglobin_max  \\\n",
       "0                    2.800                9.800               14.500   \n",
       "1                    3.100                8.500               10.900   \n",
       "2                    3.700                9.100               11.800   \n",
       "3                    2.000                9.000               10.900   \n",
       "4                    3.400                8.800               10.700   \n",
       "...                    ...                  ...                  ...   \n",
       "10229                3.100                8.300                9.800   \n",
       "10230                3.100                7.900               10.900   \n",
       "10231                3.100                7.400               10.900   \n",
       "10232                3.100                8.600               10.900   \n",
       "10233                3.100                8.300               10.900   \n",
       "\n",
       "                h1_mbp_min  ...       d1_glucose_min                  age  \\\n",
       "0                   80.000  ...               97.000               72.000   \n",
       "1                   94.000  ...               73.000               86.000   \n",
       "2                  117.000  ...               84.000               72.000   \n",
       "3                   74.000  ...               84.000               66.000   \n",
       "4                   89.000  ...               99.000               89.000   \n",
       "...                    ...  ...                  ...                  ...   \n",
       "10229               96.000  ...               96.000               36.000   \n",
       "10230               74.000  ...               94.000               61.000   \n",
       "10231               73.000  ...              150.000               74.000   \n",
       "10232               89.000  ...               98.000               90.000   \n",
       "10233               88.000  ...               99.000               30.000   \n",
       "\n",
       "            d1_lactate_max                  bmi               icu_id  \\\n",
       "0                    1.000               26.600               82.000   \n",
       "1                    1.000               26.600               82.000   \n",
       "2                    1.000               26.600               82.000   \n",
       "3                    1.000               26.600               82.000   \n",
       "4                    1.000               26.600               82.000   \n",
       "...                    ...                  ...                  ...   \n",
       "10229                1.000               37.500            1,108.000   \n",
       "10230                1.000               32.100            1,108.000   \n",
       "10231                1.000               22.700            1,108.000   \n",
       "10232                1.000               19.900            1,108.000   \n",
       "10233                1.000               25.600            1,108.000   \n",
       "\n",
       "         gcs_verbal_apache     gcs_motor_apache           arf_apache  \\\n",
       "0                    5.000                6.000                0.000   \n",
       "1                    5.000                6.000                0.000   \n",
       "2                    5.000                6.000                0.000   \n",
       "3                    4.000                6.000                0.000   \n",
       "4                    5.000                6.000                0.000   \n",
       "...                    ...                  ...                  ...   \n",
       "10229                5.000                6.000                0.000   \n",
       "10230                5.000                6.000                0.000   \n",
       "10231                5.000                6.000                0.000   \n",
       "10232                4.000                6.000                0.000   \n",
       "10233                1.000                5.000                0.000   \n",
       "\n",
       "         ventilated_apache       d1_glucose_max  \n",
       "0                    0.000              104.000  \n",
       "1                    0.000              102.000  \n",
       "2                    0.000              141.000  \n",
       "3                    1.000               84.000  \n",
       "4                    0.000              159.000  \n",
       "...                    ...                  ...  \n",
       "10229                0.000               96.000  \n",
       "10230                0.000               94.000  \n",
       "10231                0.000              150.000  \n",
       "10232                0.000               98.000  \n",
       "10233                0.000              111.000  \n",
       "\n",
       "[10234 rows x 139 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_HO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#predict probabilities on submission hold out data\n",
    "predict_HO = model_rd.predict_proba(X_HO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.97537696, 0.02462303],\n",
       "       [0.9361468 , 0.0638532 ],\n",
       "       [0.8931618 , 0.1068382 ],\n",
       "       ...,\n",
       "       [0.96683776, 0.03316225],\n",
       "       [0.9892555 , 0.01074453],\n",
       "       [0.9943823 , 0.00561768]], dtype=float32)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_HO "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_df = pd.DataFrame(predict_HO[:,1].round(3),HO.encounter_id)\n",
    "submission_df = submission_df.sort_values('encounter_id')\n",
    "submission_df.columns=['diabetes_mellitus']\n",
    "#submission_df = submission_df.reset_index()\n",
    "#create submission csv\n",
    "submission_df.to_csv(\"wids2021_choksi_huilin_leonard_narayan_0227_im.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Float64Index: 10234 entries, 135000.0 to 146000.0\n",
      "Data columns (total 1 columns):\n",
      " #   Column             Non-Null Count  Dtype  \n",
      "---  ------             --------------  -----  \n",
      " 0   diabetes_mellitus  10234 non-null  float32\n",
      "dtypes: float32(1)\n",
      "memory usage: 119.9 KB\n"
     ]
    }
   ],
   "source": [
    "#check contents to make sure\n",
    "submission_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>diabetes_mellitus</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>encounter_id</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>145,996.000</th>\n",
       "      <td>0.098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145,997.000</th>\n",
       "      <td>0.142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145,998.000</th>\n",
       "      <td>0.234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145,999.000</th>\n",
       "      <td>0.046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146,000.000</th>\n",
       "      <td>0.714</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                diabetes_mellitus\n",
       "encounter_id                     \n",
       "145,996.000                 0.098\n",
       "145,997.000                 0.142\n",
       "145,998.000                 0.234\n",
       "145,999.000                 0.046\n",
       "146,000.000                 0.714"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission_df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'encounter_id'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mget_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   2894\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2895\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2896\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'encounter_id'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-35-2db03565dfa4>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0msubmission_df\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"encounter_id\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_numeric\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msubmission_df\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"encounter_id\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   2900\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2901\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2902\u001b[1;33m             \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2903\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2904\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mget_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   2895\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2896\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2897\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2898\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2899\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mtolerance\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'encounter_id'"
     ]
    }
   ],
   "source": [
    "submission_df[\"encounter_id\"] = pd.to_numeric(submission_df[\"encounter_id\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deep Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# neural network with keras\n",
    "from numpy import loadtxt\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation\n",
    "from keras.optimizers import SGD\n",
    "import keras\n",
    "import keras.utils\n",
    "from keras import utils as np_utils\n",
    "from tensorflow.keras.wrappers.scikit_learn import KerasClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create new training and test data with reduced data and check accuracy\n",
    "X_train_rd, X_test_rd, y_train, y_test = train_test_split(reduced_data, Y, train_size=0.70,stratify=Y,random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>leukemia</th>\n",
       "      <th>h1_temp_min</th>\n",
       "      <th>hepatic_failure</th>\n",
       "      <th>d1_inr_min</th>\n",
       "      <th>h1_sodium_min</th>\n",
       "      <th>immunosuppression</th>\n",
       "      <th>d1_albumin_max</th>\n",
       "      <th>d1_calcium_max</th>\n",
       "      <th>h1_hemaglobin_max</th>\n",
       "      <th>h1_mbp_min</th>\n",
       "      <th>...</th>\n",
       "      <th>d1_glucose_min</th>\n",
       "      <th>age</th>\n",
       "      <th>d1_lactate_max</th>\n",
       "      <th>bmi</th>\n",
       "      <th>icu_id</th>\n",
       "      <th>gcs_verbal_apache</th>\n",
       "      <th>gcs_motor_apache</th>\n",
       "      <th>arf_apache</th>\n",
       "      <th>ventilated_apache</th>\n",
       "      <th>d1_glucose_max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>34731</th>\n",
       "      <td>0.000</td>\n",
       "      <td>36.400</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.100</td>\n",
       "      <td>139.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>3.100</td>\n",
       "      <td>9.500</td>\n",
       "      <td>10.900</td>\n",
       "      <td>85.000</td>\n",
       "      <td>...</td>\n",
       "      <td>111.000</td>\n",
       "      <td>67.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>34.422</td>\n",
       "      <td>451.000</td>\n",
       "      <td>5.000</td>\n",
       "      <td>6.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>111.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32864</th>\n",
       "      <td>0.000</td>\n",
       "      <td>36.800</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>139.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>3.200</td>\n",
       "      <td>7.100</td>\n",
       "      <td>10.900</td>\n",
       "      <td>105.000</td>\n",
       "      <td>...</td>\n",
       "      <td>94.000</td>\n",
       "      <td>34.000</td>\n",
       "      <td>4.000</td>\n",
       "      <td>50.659</td>\n",
       "      <td>430.000</td>\n",
       "      <td>5.000</td>\n",
       "      <td>6.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>96.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77628</th>\n",
       "      <td>0.000</td>\n",
       "      <td>35.800</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.100</td>\n",
       "      <td>138.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>3.100</td>\n",
       "      <td>8.300</td>\n",
       "      <td>16.400</td>\n",
       "      <td>100.000</td>\n",
       "      <td>...</td>\n",
       "      <td>87.000</td>\n",
       "      <td>35.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>28.001</td>\n",
       "      <td>829.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>106.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120480</th>\n",
       "      <td>0.000</td>\n",
       "      <td>37.900</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.100</td>\n",
       "      <td>139.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>3.100</td>\n",
       "      <td>7.600</td>\n",
       "      <td>10.900</td>\n",
       "      <td>81.000</td>\n",
       "      <td>...</td>\n",
       "      <td>127.000</td>\n",
       "      <td>49.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>29.670</td>\n",
       "      <td>1,068.000</td>\n",
       "      <td>5.000</td>\n",
       "      <td>6.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>149.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122407</th>\n",
       "      <td>0.000</td>\n",
       "      <td>36.300</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.970</td>\n",
       "      <td>142.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>4.300</td>\n",
       "      <td>9.000</td>\n",
       "      <td>12.100</td>\n",
       "      <td>74.000</td>\n",
       "      <td>...</td>\n",
       "      <td>92.000</td>\n",
       "      <td>81.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>67.815</td>\n",
       "      <td>1,063.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>3.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>94.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122226</th>\n",
       "      <td>0.000</td>\n",
       "      <td>34.500</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.100</td>\n",
       "      <td>139.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>3.700</td>\n",
       "      <td>8.200</td>\n",
       "      <td>13.100</td>\n",
       "      <td>60.000</td>\n",
       "      <td>...</td>\n",
       "      <td>107.000</td>\n",
       "      <td>67.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>33.701</td>\n",
       "      <td>1,071.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>3.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>107.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20005</th>\n",
       "      <td>0.000</td>\n",
       "      <td>36.300</td>\n",
       "      <td>0.000</td>\n",
       "      <td>2.600</td>\n",
       "      <td>139.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>3.300</td>\n",
       "      <td>9.200</td>\n",
       "      <td>10.900</td>\n",
       "      <td>57.000</td>\n",
       "      <td>...</td>\n",
       "      <td>127.000</td>\n",
       "      <td>78.000</td>\n",
       "      <td>1.400</td>\n",
       "      <td>33.047</td>\n",
       "      <td>408.000</td>\n",
       "      <td>5.000</td>\n",
       "      <td>6.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>281.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8081</th>\n",
       "      <td>0.000</td>\n",
       "      <td>36.614</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.100</td>\n",
       "      <td>133.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>3.500</td>\n",
       "      <td>8.200</td>\n",
       "      <td>10.000</td>\n",
       "      <td>92.000</td>\n",
       "      <td>...</td>\n",
       "      <td>90.000</td>\n",
       "      <td>49.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>27.385</td>\n",
       "      <td>133.000</td>\n",
       "      <td>5.000</td>\n",
       "      <td>6.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>318.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100543</th>\n",
       "      <td>0.000</td>\n",
       "      <td>36.600</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.100</td>\n",
       "      <td>139.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>3.100</td>\n",
       "      <td>7.800</td>\n",
       "      <td>10.900</td>\n",
       "      <td>84.000</td>\n",
       "      <td>...</td>\n",
       "      <td>191.000</td>\n",
       "      <td>77.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>29.863</td>\n",
       "      <td>978.000</td>\n",
       "      <td>5.000</td>\n",
       "      <td>6.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>264.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86447</th>\n",
       "      <td>0.000</td>\n",
       "      <td>37.200</td>\n",
       "      <td>0.000</td>\n",
       "      <td>6.127</td>\n",
       "      <td>139.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>2.200</td>\n",
       "      <td>7.300</td>\n",
       "      <td>10.900</td>\n",
       "      <td>79.000</td>\n",
       "      <td>...</td>\n",
       "      <td>107.000</td>\n",
       "      <td>57.000</td>\n",
       "      <td>1.200</td>\n",
       "      <td>37.309</td>\n",
       "      <td>869.000</td>\n",
       "      <td>4.000</td>\n",
       "      <td>5.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>135.000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>91109 rows × 139 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   leukemia          h1_temp_min      hepatic_failure  \\\n",
       "34731                 0.000               36.400                0.000   \n",
       "32864                 0.000               36.800                0.000   \n",
       "77628                 0.000               35.800                0.000   \n",
       "120480                0.000               37.900                0.000   \n",
       "122407                0.000               36.300                0.000   \n",
       "...                     ...                  ...                  ...   \n",
       "122226                0.000               34.500                0.000   \n",
       "20005                 0.000               36.300                0.000   \n",
       "8081                  0.000               36.614                0.000   \n",
       "100543                0.000               36.600                0.000   \n",
       "86447                 0.000               37.200                0.000   \n",
       "\n",
       "                 d1_inr_min        h1_sodium_min    immunosuppression  \\\n",
       "34731                 1.100              139.000                0.000   \n",
       "32864                 1.000              139.000                0.000   \n",
       "77628                 1.100              138.000                0.000   \n",
       "120480                1.100              139.000                0.000   \n",
       "122407                0.970              142.000                0.000   \n",
       "...                     ...                  ...                  ...   \n",
       "122226                1.100              139.000                0.000   \n",
       "20005                 2.600              139.000                0.000   \n",
       "8081                  1.100              133.000                0.000   \n",
       "100543                1.100              139.000                0.000   \n",
       "86447                 6.127              139.000                0.000   \n",
       "\n",
       "             d1_albumin_max       d1_calcium_max    h1_hemaglobin_max  \\\n",
       "34731                 3.100                9.500               10.900   \n",
       "32864                 3.200                7.100               10.900   \n",
       "77628                 3.100                8.300               16.400   \n",
       "120480                3.100                7.600               10.900   \n",
       "122407                4.300                9.000               12.100   \n",
       "...                     ...                  ...                  ...   \n",
       "122226                3.700                8.200               13.100   \n",
       "20005                 3.300                9.200               10.900   \n",
       "8081                  3.500                8.200               10.000   \n",
       "100543                3.100                7.800               10.900   \n",
       "86447                 2.200                7.300               10.900   \n",
       "\n",
       "                 h1_mbp_min  ...       d1_glucose_min                  age  \\\n",
       "34731                85.000  ...              111.000               67.000   \n",
       "32864               105.000  ...               94.000               34.000   \n",
       "77628               100.000  ...               87.000               35.000   \n",
       "120480               81.000  ...              127.000               49.000   \n",
       "122407               74.000  ...               92.000               81.000   \n",
       "...                     ...  ...                  ...                  ...   \n",
       "122226               60.000  ...              107.000               67.000   \n",
       "20005                57.000  ...              127.000               78.000   \n",
       "8081                 92.000  ...               90.000               49.000   \n",
       "100543               84.000  ...              191.000               77.000   \n",
       "86447                79.000  ...              107.000               57.000   \n",
       "\n",
       "             d1_lactate_max                  bmi               icu_id  \\\n",
       "34731                 1.000               34.422              451.000   \n",
       "32864                 4.000               50.659              430.000   \n",
       "77628                 1.000               28.001              829.000   \n",
       "120480                1.000               29.670            1,068.000   \n",
       "122407                1.000               67.815            1,063.000   \n",
       "...                     ...                  ...                  ...   \n",
       "122226                1.000               33.701            1,071.000   \n",
       "20005                 1.400               33.047              408.000   \n",
       "8081                  1.000               27.385              133.000   \n",
       "100543                1.000               29.863              978.000   \n",
       "86447                 1.200               37.309              869.000   \n",
       "\n",
       "          gcs_verbal_apache     gcs_motor_apache           arf_apache  \\\n",
       "34731                 5.000                6.000                0.000   \n",
       "32864                 5.000                6.000                0.000   \n",
       "77628                 1.000                1.000                0.000   \n",
       "120480                5.000                6.000                0.000   \n",
       "122407                1.000                3.000                0.000   \n",
       "...                     ...                  ...                  ...   \n",
       "122226                1.000                3.000                0.000   \n",
       "20005                 5.000                6.000                0.000   \n",
       "8081                  5.000                6.000                0.000   \n",
       "100543                5.000                6.000                0.000   \n",
       "86447                 4.000                5.000                0.000   \n",
       "\n",
       "          ventilated_apache       d1_glucose_max  \n",
       "34731                 0.000              111.000  \n",
       "32864                 0.000               96.000  \n",
       "77628                 1.000              106.000  \n",
       "120480                0.000              149.000  \n",
       "122407                1.000               94.000  \n",
       "...                     ...                  ...  \n",
       "122226                1.000              107.000  \n",
       "20005                 1.000              281.000  \n",
       "8081                  0.000              318.000  \n",
       "100543                0.000              264.000  \n",
       "86447                 0.000              135.000  \n",
       "\n",
       "[91109 rows x 139 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_rd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler().fit(X_train_rd)\n",
    "X_train = scaler.transform(X_train_rd)\n",
    "X_test = scaler.transform(X_test_rd)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Dense(64, activation='relu', input_shape=(139,)))\n",
    "model.add(Dense(32, activation='relu'))\n",
    "opt = keras.optimizers.Adam(learning_rate = 0.001)\n",
    "\n",
    "model.add(Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/80\n",
      "91109/91109 [==============================] - 98s 1ms/step - loss: 0.4054 - accuracy: 0.8179\n",
      "Epoch 2/80\n",
      "91109/91109 [==============================] - 89s 973us/step - loss: 0.3904 - accuracy: 0.8237\n",
      "Epoch 3/80\n",
      "91109/91109 [==============================] - 87s 950us/step - loss: 0.3851 - accuracy: 0.8262\n",
      "Epoch 4/80\n",
      "91109/91109 [==============================] - 87s 953us/step - loss: 0.3823 - accuracy: 0.8265\n",
      "Epoch 5/80\n",
      "91109/91109 [==============================] - 87s 959us/step - loss: 0.3795 - accuracy: 0.8285\n",
      "Epoch 6/80\n",
      "91109/91109 [==============================] - 85s 928us/step - loss: 0.3763 - accuracy: 0.8299\n",
      "Epoch 7/80\n",
      "91109/91109 [==============================] - 84s 919us/step - loss: 0.3745 - accuracy: 0.8305\n",
      "Epoch 8/80\n",
      "91109/91109 [==============================] - 82s 903us/step - loss: 0.3722 - accuracy: 0.8303\n",
      "Epoch 9/80\n",
      "91109/91109 [==============================] - 84s 924us/step - loss: 0.3707 - accuracy: 0.8312\n",
      "Epoch 10/80\n",
      "91109/91109 [==============================] - 87s 950us/step - loss: 0.3684 - accuracy: 0.8320\n",
      "Epoch 11/80\n",
      "91109/91109 [==============================] - 87s 959us/step - loss: 0.3673 - accuracy: 0.8339\n",
      "Epoch 12/80\n",
      "91109/91109 [==============================] - 88s 966us/step - loss: 0.3649 - accuracy: 0.8345\n",
      "Epoch 13/80\n",
      "91109/91109 [==============================] - 84s 917us/step - loss: 0.3633 - accuracy: 0.8344\n",
      "Epoch 14/80\n",
      "91109/91109 [==============================] - 87s 952us/step - loss: 0.3622 - accuracy: 0.8352\n",
      "Epoch 15/80\n",
      "91109/91109 [==============================] - 87s 956us/step - loss: 0.3617 - accuracy: 0.8358\n",
      "Epoch 16/80\n",
      "91109/91109 [==============================] - 88s 965us/step - loss: 0.3607 - accuracy: 0.8368\n",
      "Epoch 17/80\n",
      "91109/91109 [==============================] - 86s 948us/step - loss: 0.3590 - accuracy: 0.8371\n",
      "Epoch 18/80\n",
      "91109/91109 [==============================] - 85s 929us/step - loss: 0.3578 - accuracy: 0.8372\n",
      "Epoch 19/80\n",
      "91109/91109 [==============================] - 86s 942us/step - loss: 0.3582 - accuracy: 0.8385\n",
      "Epoch 20/80\n",
      "91109/91109 [==============================] - 88s 969us/step - loss: 0.3576 - accuracy: 0.8385\n",
      "Epoch 21/80\n",
      "91109/91109 [==============================] - 88s 965us/step - loss: 0.3561 - accuracy: 0.8388\n",
      "Epoch 22/80\n",
      "91109/91109 [==============================] - 88s 961us/step - loss: 0.3557 - accuracy: 0.8390\n",
      "Epoch 23/80\n",
      "91109/91109 [==============================] - 86s 942us/step - loss: 0.3547 - accuracy: 0.8396\n",
      "Epoch 24/80\n",
      "91109/91109 [==============================] - 84s 923us/step - loss: 0.3550 - accuracy: 0.8393\n",
      "Epoch 25/80\n",
      "91109/91109 [==============================] - 84s 922us/step - loss: 0.3549 - accuracy: 0.8394\n",
      "Epoch 26/80\n",
      "91109/91109 [==============================] - 768s 8ms/step - loss: 0.3540 - accuracy: 0.8404\n",
      "Epoch 27/80\n",
      "91109/91109 [==============================] - 90s 984us/step - loss: 0.3529 - accuracy: 0.8409\n",
      "Epoch 28/80\n",
      "91109/91109 [==============================] - 88s 966us/step - loss: 0.3537 - accuracy: 0.8402\n",
      "Epoch 29/80\n",
      "91109/91109 [==============================] - 87s 955us/step - loss: 0.3522 - accuracy: 0.8408\n",
      "Epoch 30/80\n",
      "91109/91109 [==============================] - 88s 970us/step - loss: 0.3523 - accuracy: 0.8406\n",
      "Epoch 31/80\n",
      "91109/91109 [==============================] - 88s 961us/step - loss: 0.3525 - accuracy: 0.8416\n",
      "Epoch 32/80\n",
      "91109/91109 [==============================] - 87s 949us/step - loss: 0.3516 - accuracy: 0.8417\n",
      "Epoch 33/80\n",
      "91109/91109 [==============================] - 87s 953us/step - loss: 0.3517 - accuracy: 0.8421\n",
      "Epoch 34/80\n",
      "91109/91109 [==============================] - 87s 952us/step - loss: 0.3520 - accuracy: 0.8421\n",
      "Epoch 35/80\n",
      "91109/91109 [==============================] - 87s 954us/step - loss: 0.3502 - accuracy: 0.8416\n",
      "Epoch 36/80\n",
      "91109/91109 [==============================] - 87s 957us/step - loss: 0.3508 - accuracy: 0.8421\n",
      "Epoch 37/80\n",
      "91109/91109 [==============================] - 87s 956us/step - loss: 0.3519 - accuracy: 0.8418\n",
      "Epoch 38/80\n",
      "91109/91109 [==============================] - 87s 954us/step - loss: 0.3516 - accuracy: 0.8415\n",
      "Epoch 39/80\n",
      "91109/91109 [==============================] - 89s 976us/step - loss: 0.3510 - accuracy: 0.8423\n",
      "Epoch 40/80\n",
      "91109/91109 [==============================] - 88s 964us/step - loss: 0.3507 - accuracy: 0.8433\n",
      "Epoch 41/80\n",
      "91109/91109 [==============================] - 88s 963us/step - loss: 0.3509 - accuracy: 0.8426\n",
      "Epoch 42/80\n",
      "91109/91109 [==============================] - 88s 961us/step - loss: 0.3530 - accuracy: 0.8421\n",
      "Epoch 43/80\n",
      "91109/91109 [==============================] - 87s 958us/step - loss: 0.3558 - accuracy: 0.8420\n",
      "Epoch 44/80\n",
      "91109/91109 [==============================] - 88s 966us/step - loss: 0.3527 - accuracy: 0.8422\n",
      "Epoch 45/80\n",
      "91109/91109 [==============================] - 83s 913us/step - loss: 0.3533 - accuracy: 0.8427\n",
      "Epoch 46/80\n",
      "91109/91109 [==============================] - 83s 916us/step - loss: 0.3525 - accuracy: 0.8419\n",
      "Epoch 47/80\n",
      "91109/91109 [==============================] - 86s 939us/step - loss: 0.3530 - accuracy: 0.8420\n",
      "Epoch 48/80\n",
      "91109/91109 [==============================] - 86s 944us/step - loss: 0.3525 - accuracy: 0.8419\n",
      "Epoch 49/80\n",
      "91109/91109 [==============================] - 86s 944us/step - loss: 0.3533 - accuracy: 0.8421\n",
      "Epoch 50/80\n",
      "91109/91109 [==============================] - 87s 956us/step - loss: 0.3549 - accuracy: 0.8418\n",
      "Epoch 51/80\n",
      "91109/91109 [==============================] - 85s 935us/step - loss: 0.3552 - accuracy: 0.8413\n",
      "Epoch 52/80\n",
      "91109/91109 [==============================] - 84s 920us/step - loss: 0.3550 - accuracy: 0.8429\n",
      "Epoch 53/80\n",
      "91109/91109 [==============================] - 84s 927us/step - loss: 0.3571 - accuracy: 0.8425\n",
      "Epoch 54/80\n",
      "91109/91109 [==============================] - 85s 935us/step - loss: 0.3551 - accuracy: 0.8427\n",
      "Epoch 55/80\n",
      "91109/91109 [==============================] - 84s 926us/step - loss: 0.3550 - accuracy: 0.8423\n",
      "Epoch 56/80\n",
      "91109/91109 [==============================] - 84s 927us/step - loss: 0.3527 - accuracy: 0.8427\n",
      "Epoch 57/80\n",
      "91109/91109 [==============================] - 84s 925us/step - loss: 0.3562 - accuracy: 0.8428\n",
      "Epoch 58/80\n",
      "91109/91109 [==============================] - 83s 916us/step - loss: 0.3562 - accuracy: 0.8418\n",
      "Epoch 59/80\n",
      "91109/91109 [==============================] - 85s 938us/step - loss: 0.3538 - accuracy: 0.8439\n",
      "Epoch 60/80\n",
      "91109/91109 [==============================] - 87s 960us/step - loss: 0.3556 - accuracy: 0.8431\n",
      "Epoch 61/80\n",
      "91109/91109 [==============================] - 87s 952us/step - loss: 0.3556 - accuracy: 0.8440s - loss: 0.3557 - \n",
      "Epoch 62/80\n",
      "91109/91109 [==============================] - 87s 951us/step - loss: 0.3550 - accuracy: 0.8437\n",
      "Epoch 63/80\n",
      "91109/91109 [==============================] - 86s 947us/step - loss: 0.3537 - accuracy: 0.8441\n",
      "Epoch 64/80\n",
      "91109/91109 [==============================] - 86s 944us/step - loss: 0.3516 - accuracy: 0.8448\n",
      "Epoch 65/80\n",
      "91109/91109 [==============================] - 88s 964us/step - loss: 0.3546 - accuracy: 0.8441\n",
      "Epoch 66/80\n",
      "91109/91109 [==============================] - 87s 958us/step - loss: 0.3539 - accuracy: 0.8450\n",
      "Epoch 67/80\n",
      "91109/91109 [==============================] - 88s 963us/step - loss: 0.3509 - accuracy: 0.8453\n",
      "Epoch 68/80\n",
      "91109/91109 [==============================] - 88s 963us/step - loss: 0.3553 - accuracy: 0.8448\n",
      "Epoch 69/80\n",
      "91109/91109 [==============================] - 88s 965us/step - loss: 0.3553 - accuracy: 0.8454\n",
      "Epoch 70/80\n",
      "91109/91109 [==============================] - 87s 959us/step - loss: 0.3555 - accuracy: 0.8450\n",
      "Epoch 71/80\n",
      "91109/91109 [==============================] - 88s 965us/step - loss: 0.3555 - accuracy: 0.8454\n",
      "Epoch 72/80\n",
      "91109/91109 [==============================] - 88s 962us/step - loss: 0.3548 - accuracy: 0.8450\n",
      "Epoch 73/80\n",
      "91109/91109 [==============================] - 89s 973us/step - loss: 0.3556 - accuracy: 0.8453\n",
      "Epoch 74/80\n",
      "91109/91109 [==============================] - 86s 944us/step - loss: 0.3544 - accuracy: 0.8450\n",
      "Epoch 75/80\n",
      "91109/91109 [==============================] - 86s 939us/step - loss: 0.3539 - accuracy: 0.8456\n",
      "Epoch 76/80\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "91109/91109 [==============================] - 85s 938us/step - loss: 0.3619 - accuracy: 0.8451\n",
      "Epoch 77/80\n",
      "91109/91109 [==============================] - 86s 942us/step - loss: 0.3598 - accuracy: 0.8449\n",
      "Epoch 78/80\n",
      "91109/91109 [==============================] - 87s 950us/step - loss: 0.3591 - accuracy: 0.8454\n",
      "Epoch 79/80\n",
      "91109/91109 [==============================] - 86s 939us/step - loss: 0.3608 - accuracy: 0.8449\n",
      "Epoch 80/80\n",
      "91109/91109 [==============================] - 87s 952us/step - loss: 0.3569 - accuracy: 0.8458\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1b823710d60>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer= opt,\n",
    "              metrics=['accuracy'])\n",
    "                   \n",
    "model.fit(X_train, y_train,epochs=80, batch_size=1, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Customized Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "def FindLayerNodesLinear(n_layers, first_layer_nodes, last_layer_nodes):\n",
    "    layers = []\n",
    "    \n",
    "    nodes_increment = (last_layer_nodes - first_layer_nodes)/ (n_layers-1)\n",
    "    nodes = first_layer_nodes\n",
    "    for i in range(1, n_layers+1):\n",
    "        layers.append(math.ceil(nodes))\n",
    "        nodes = nodes + nodes_increment\n",
    "    \n",
    "    return layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[50, 40, 30, 20, 10]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "FindLayerNodesLinear(5, 50, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createmodel(n_layers, first_layer_nodes, last_layer_nodes, activation_func, loss_func):\n",
    "    model = Sequential()\n",
    "    n_nodes = FindLayerNodesLinear(n_layers, first_layer_nodes, last_layer_nodes)\n",
    "    for i in range(1, n_layers):\n",
    "        if i==1:\n",
    "            model.add(Dense(first_layer_nodes, input_dim=X_train.shape[1], activation=activation_func))\n",
    "        else:\n",
    "            model.add(Dense(n_nodes[i-1], activation=activation_func))\n",
    "            \n",
    "    #Finally, the output layer should have a single node in binary classification\n",
    "    model.add(Dense(1, activation=activation_func))\n",
    "    model.compile(optimizer='adam', loss=loss_func, metrics = [\"accuracy\"]) #note: metrics could also be 'mse'\n",
    "    \n",
    "    return model\n",
    "\n",
    "##Wrap model into scikit-learn\n",
    "model =  KerasClassifier(build_fn=createmodel, verbose = False)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "activation_funcs = ['sigmoid', 'relu', 'tanh'] \n",
    "loss_funcs = ['binary_crossentropy','hinge']\n",
    "param_grid = dict(n_layers=[2,3], first_layer_nodes = [64,32,16], last_layer_nodes = [4],  activation_func = activation_funcs, loss_func = loss_funcs, batch_size = [100], epochs = [20,60])\n",
    "grid = GridSearchCV(estimator = model, param_grid = param_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Apply Keras model to make prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "HO_i = pd.read_csv('UnlabeledWiDS2021.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>encounter_id</th>\n",
       "      <th>hospital_id</th>\n",
       "      <th>age</th>\n",
       "      <th>bmi</th>\n",
       "      <th>elective_surgery</th>\n",
       "      <th>ethnicity</th>\n",
       "      <th>gender</th>\n",
       "      <th>height</th>\n",
       "      <th>hospital_admit_source</th>\n",
       "      <th>...</th>\n",
       "      <th>h1_arterial_po2_min</th>\n",
       "      <th>h1_pao2fio2ratio_max</th>\n",
       "      <th>h1_pao2fio2ratio_min</th>\n",
       "      <th>aids</th>\n",
       "      <th>cirrhosis</th>\n",
       "      <th>hepatic_failure</th>\n",
       "      <th>immunosuppression</th>\n",
       "      <th>leukemia</th>\n",
       "      <th>lymphoma</th>\n",
       "      <th>solid_tumor_with_metastasis</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>144740</td>\n",
       "      <td>10141</td>\n",
       "      <td>72</td>\n",
       "      <td>nan</td>\n",
       "      <td>0</td>\n",
       "      <td>Caucasian</td>\n",
       "      <td>F</td>\n",
       "      <td>152.400</td>\n",
       "      <td>Floor</td>\n",
       "      <td>...</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>141990</td>\n",
       "      <td>10141</td>\n",
       "      <td>86</td>\n",
       "      <td>nan</td>\n",
       "      <td>0</td>\n",
       "      <td>Caucasian</td>\n",
       "      <td>F</td>\n",
       "      <td>175.300</td>\n",
       "      <td>Emergency Department</td>\n",
       "      <td>...</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>142038</td>\n",
       "      <td>10141</td>\n",
       "      <td>72</td>\n",
       "      <td>nan</td>\n",
       "      <td>0</td>\n",
       "      <td>Caucasian</td>\n",
       "      <td>F</td>\n",
       "      <td>162.600</td>\n",
       "      <td>Floor</td>\n",
       "      <td>...</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>138628</td>\n",
       "      <td>10141</td>\n",
       "      <td>66</td>\n",
       "      <td>nan</td>\n",
       "      <td>0</td>\n",
       "      <td>Caucasian</td>\n",
       "      <td>M</td>\n",
       "      <td>177.800</td>\n",
       "      <td>Floor</td>\n",
       "      <td>...</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>141682</td>\n",
       "      <td>10141</td>\n",
       "      <td>89</td>\n",
       "      <td>nan</td>\n",
       "      <td>0</td>\n",
       "      <td>Caucasian</td>\n",
       "      <td>M</td>\n",
       "      <td>170.200</td>\n",
       "      <td>Direct Admit</td>\n",
       "      <td>...</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10229</th>\n",
       "      <td>10230</td>\n",
       "      <td>143750</td>\n",
       "      <td>10140</td>\n",
       "      <td>36</td>\n",
       "      <td>37.500</td>\n",
       "      <td>0</td>\n",
       "      <td>Caucasian</td>\n",
       "      <td>F</td>\n",
       "      <td>170.100</td>\n",
       "      <td>Floor</td>\n",
       "      <td>...</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10230</th>\n",
       "      <td>10231</td>\n",
       "      <td>143813</td>\n",
       "      <td>10140</td>\n",
       "      <td>61</td>\n",
       "      <td>32.100</td>\n",
       "      <td>0</td>\n",
       "      <td>Caucasian</td>\n",
       "      <td>F</td>\n",
       "      <td>160.000</td>\n",
       "      <td>Emergency Department</td>\n",
       "      <td>...</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10231</th>\n",
       "      <td>10232</td>\n",
       "      <td>137126</td>\n",
       "      <td>10140</td>\n",
       "      <td>74</td>\n",
       "      <td>22.700</td>\n",
       "      <td>0</td>\n",
       "      <td>Caucasian</td>\n",
       "      <td>F</td>\n",
       "      <td>165.100</td>\n",
       "      <td>Step-Down Unit (SDU)</td>\n",
       "      <td>...</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10232</th>\n",
       "      <td>10233</td>\n",
       "      <td>135652</td>\n",
       "      <td>10140</td>\n",
       "      <td>90</td>\n",
       "      <td>19.900</td>\n",
       "      <td>0</td>\n",
       "      <td>Caucasian</td>\n",
       "      <td>F</td>\n",
       "      <td>160.000</td>\n",
       "      <td>Emergency Department</td>\n",
       "      <td>...</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10233</th>\n",
       "      <td>10234</td>\n",
       "      <td>136852</td>\n",
       "      <td>10140</td>\n",
       "      <td>30</td>\n",
       "      <td>25.600</td>\n",
       "      <td>0</td>\n",
       "      <td>Caucasian</td>\n",
       "      <td>M</td>\n",
       "      <td>177.800</td>\n",
       "      <td>Emergency Department</td>\n",
       "      <td>...</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10234 rows × 180 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Unnamed: 0  encounter_id  hospital_id  age                  bmi  \\\n",
       "0               1        144740        10141   72                  nan   \n",
       "1               2        141990        10141   86                  nan   \n",
       "2               3        142038        10141   72                  nan   \n",
       "3               4        138628        10141   66                  nan   \n",
       "4               5        141682        10141   89                  nan   \n",
       "...           ...           ...          ...  ...                  ...   \n",
       "10229       10230        143750        10140   36               37.500   \n",
       "10230       10231        143813        10140   61               32.100   \n",
       "10231       10232        137126        10140   74               22.700   \n",
       "10232       10233        135652        10140   90               19.900   \n",
       "10233       10234        136852        10140   30               25.600   \n",
       "\n",
       "       elective_surgery  ethnicity gender               height  \\\n",
       "0                     0  Caucasian      F              152.400   \n",
       "1                     0  Caucasian      F              175.300   \n",
       "2                     0  Caucasian      F              162.600   \n",
       "3                     0  Caucasian      M              177.800   \n",
       "4                     0  Caucasian      M              170.200   \n",
       "...                 ...        ...    ...                  ...   \n",
       "10229                 0  Caucasian      F              170.100   \n",
       "10230                 0  Caucasian      F              160.000   \n",
       "10231                 0  Caucasian      F              165.100   \n",
       "10232                 0  Caucasian      F              160.000   \n",
       "10233                 0  Caucasian      M              177.800   \n",
       "\n",
       "      hospital_admit_source  ...  h1_arterial_po2_min  h1_pao2fio2ratio_max  \\\n",
       "0                     Floor  ...                  nan                   nan   \n",
       "1      Emergency Department  ...                  nan                   nan   \n",
       "2                     Floor  ...                  nan                   nan   \n",
       "3                     Floor  ...                  nan                   nan   \n",
       "4              Direct Admit  ...                  nan                   nan   \n",
       "...                     ...  ...                  ...                   ...   \n",
       "10229                 Floor  ...                  nan                   nan   \n",
       "10230  Emergency Department  ...                  nan                   nan   \n",
       "10231  Step-Down Unit (SDU)  ...                  nan                   nan   \n",
       "10232  Emergency Department  ...                  nan                   nan   \n",
       "10233  Emergency Department  ...                  nan                   nan   \n",
       "\n",
       "      h1_pao2fio2ratio_min aids  cirrhosis  hepatic_failure  \\\n",
       "0                      nan    0          0                0   \n",
       "1                      nan    0          0                0   \n",
       "2                      nan    0          0                0   \n",
       "3                      nan    0          0                0   \n",
       "4                      nan    0          0                0   \n",
       "...                    ...  ...        ...              ...   \n",
       "10229                  nan    0          0                0   \n",
       "10230                  nan    0          0                0   \n",
       "10231                  nan    0          0                0   \n",
       "10232                  nan    0          0                0   \n",
       "10233                  nan    0          0                0   \n",
       "\n",
       "       immunosuppression  leukemia  lymphoma  solid_tumor_with_metastasis  \n",
       "0                      0         0         0                            0  \n",
       "1                      0         0         0                            0  \n",
       "2                      0         0         0                            0  \n",
       "3                      0         0         0                            0  \n",
       "4                      0         0         0                            0  \n",
       "...                  ...       ...       ...                          ...  \n",
       "10229                  0         0         0                            0  \n",
       "10230                  0         0         0                            0  \n",
       "10231                  0         0         0                            0  \n",
       "10232                  0         0         0                            0  \n",
       "10233                  0         0         0                            0  \n",
       "\n",
       "[10234 rows x 180 columns]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "HO_i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Impute missing categorical values\n",
    "#create a copy of the dataframe to impute dategorical columns missing values\n",
    "cat_impute_df = identifyCatVar(HO_i)\n",
    "#Call function to impute with most occured category\n",
    "for Columns in cat_impute_df.columns.to_list():\n",
    "    impute_nan_most_frequent_category(cat_impute_df,Columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop the categorical columsn to impute numericalvalues\n",
    "num_impute_df= HO_i.drop(columns=cat_impute_df.columns.to_list())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Impute missing numerical values\n",
    "imputer_s = SimpleImputer(missing_values=nan, strategy='most_frequent')\n",
    "# transform the dataset\n",
    "impute_data = pd.DataFrame(imputer_s.fit_transform(num_impute_df))\n",
    "# count the number of NaN values in each column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10234, 180)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## merge back to the final dataset\n",
    "#create new dataframe with imputed data and combine with categorical variables to create final imputed dataset\n",
    "impute_data.columns = num_impute_df.columns\n",
    "final_data = pd.concat([impute_data,cat_impute_df],axis=1)\n",
    "final_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "## keep columns for prediction\n",
    "HO = final_data.drop(columns=final_data.columns[0]) # removing unnamed column index\n",
    "# keep columns in train\n",
    "X_HO = HO[reduced_data.columns]\n",
    "#convert categories to strings\n",
    "X_HO = catToString(X_HO)\n",
    "#we do not know y_HO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>leukemia</th>\n",
       "      <th>h1_temp_min</th>\n",
       "      <th>hepatic_failure</th>\n",
       "      <th>d1_inr_min</th>\n",
       "      <th>h1_sodium_min</th>\n",
       "      <th>immunosuppression</th>\n",
       "      <th>d1_albumin_max</th>\n",
       "      <th>d1_calcium_max</th>\n",
       "      <th>h1_hemaglobin_max</th>\n",
       "      <th>h1_mbp_min</th>\n",
       "      <th>...</th>\n",
       "      <th>d1_glucose_min</th>\n",
       "      <th>age</th>\n",
       "      <th>d1_lactate_max</th>\n",
       "      <th>bmi</th>\n",
       "      <th>icu_id</th>\n",
       "      <th>gcs_verbal_apache</th>\n",
       "      <th>gcs_motor_apache</th>\n",
       "      <th>arf_apache</th>\n",
       "      <th>ventilated_apache</th>\n",
       "      <th>d1_glucose_max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000</td>\n",
       "      <td>36.400</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.100</td>\n",
       "      <td>132.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>2.800</td>\n",
       "      <td>9.800</td>\n",
       "      <td>14.500</td>\n",
       "      <td>80.000</td>\n",
       "      <td>...</td>\n",
       "      <td>97.000</td>\n",
       "      <td>72.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>26.600</td>\n",
       "      <td>82.000</td>\n",
       "      <td>5.000</td>\n",
       "      <td>6.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>104.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000</td>\n",
       "      <td>36.700</td>\n",
       "      <td>0.000</td>\n",
       "      <td>2.200</td>\n",
       "      <td>138.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>3.100</td>\n",
       "      <td>8.500</td>\n",
       "      <td>10.900</td>\n",
       "      <td>94.000</td>\n",
       "      <td>...</td>\n",
       "      <td>73.000</td>\n",
       "      <td>86.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>26.600</td>\n",
       "      <td>82.000</td>\n",
       "      <td>5.000</td>\n",
       "      <td>6.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>102.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000</td>\n",
       "      <td>36.400</td>\n",
       "      <td>0.000</td>\n",
       "      <td>2.400</td>\n",
       "      <td>141.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>3.700</td>\n",
       "      <td>9.100</td>\n",
       "      <td>11.800</td>\n",
       "      <td>117.000</td>\n",
       "      <td>...</td>\n",
       "      <td>84.000</td>\n",
       "      <td>72.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>26.600</td>\n",
       "      <td>82.000</td>\n",
       "      <td>5.000</td>\n",
       "      <td>6.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>141.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000</td>\n",
       "      <td>37.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.100</td>\n",
       "      <td>138.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>2.000</td>\n",
       "      <td>9.000</td>\n",
       "      <td>10.900</td>\n",
       "      <td>74.000</td>\n",
       "      <td>...</td>\n",
       "      <td>84.000</td>\n",
       "      <td>66.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>26.600</td>\n",
       "      <td>82.000</td>\n",
       "      <td>4.000</td>\n",
       "      <td>6.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>84.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000</td>\n",
       "      <td>36.600</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.100</td>\n",
       "      <td>133.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>3.400</td>\n",
       "      <td>8.800</td>\n",
       "      <td>10.700</td>\n",
       "      <td>89.000</td>\n",
       "      <td>...</td>\n",
       "      <td>99.000</td>\n",
       "      <td>89.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>26.600</td>\n",
       "      <td>82.000</td>\n",
       "      <td>5.000</td>\n",
       "      <td>6.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>159.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10229</th>\n",
       "      <td>0.000</td>\n",
       "      <td>36.500</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.070</td>\n",
       "      <td>138.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>3.100</td>\n",
       "      <td>8.300</td>\n",
       "      <td>9.800</td>\n",
       "      <td>96.000</td>\n",
       "      <td>...</td>\n",
       "      <td>96.000</td>\n",
       "      <td>36.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>37.500</td>\n",
       "      <td>1,108.000</td>\n",
       "      <td>5.000</td>\n",
       "      <td>6.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>96.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10230</th>\n",
       "      <td>0.000</td>\n",
       "      <td>36.700</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.100</td>\n",
       "      <td>138.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>3.100</td>\n",
       "      <td>7.900</td>\n",
       "      <td>10.900</td>\n",
       "      <td>74.000</td>\n",
       "      <td>...</td>\n",
       "      <td>94.000</td>\n",
       "      <td>61.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>32.100</td>\n",
       "      <td>1,108.000</td>\n",
       "      <td>5.000</td>\n",
       "      <td>6.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>94.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10231</th>\n",
       "      <td>0.000</td>\n",
       "      <td>36.700</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.100</td>\n",
       "      <td>138.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>3.100</td>\n",
       "      <td>7.400</td>\n",
       "      <td>10.900</td>\n",
       "      <td>73.000</td>\n",
       "      <td>...</td>\n",
       "      <td>150.000</td>\n",
       "      <td>74.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>22.700</td>\n",
       "      <td>1,108.000</td>\n",
       "      <td>5.000</td>\n",
       "      <td>6.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>150.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10232</th>\n",
       "      <td>0.000</td>\n",
       "      <td>36.100</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.100</td>\n",
       "      <td>138.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>3.100</td>\n",
       "      <td>8.600</td>\n",
       "      <td>10.900</td>\n",
       "      <td>89.000</td>\n",
       "      <td>...</td>\n",
       "      <td>98.000</td>\n",
       "      <td>90.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>19.900</td>\n",
       "      <td>1,108.000</td>\n",
       "      <td>4.000</td>\n",
       "      <td>6.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>98.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10233</th>\n",
       "      <td>0.000</td>\n",
       "      <td>37.100</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.100</td>\n",
       "      <td>138.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>3.100</td>\n",
       "      <td>8.300</td>\n",
       "      <td>10.900</td>\n",
       "      <td>88.000</td>\n",
       "      <td>...</td>\n",
       "      <td>99.000</td>\n",
       "      <td>30.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>25.600</td>\n",
       "      <td>1,108.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>5.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>111.000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10234 rows × 139 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  leukemia          h1_temp_min      hepatic_failure  \\\n",
       "0                    0.000               36.400                0.000   \n",
       "1                    0.000               36.700                0.000   \n",
       "2                    0.000               36.400                0.000   \n",
       "3                    0.000               37.000                0.000   \n",
       "4                    0.000               36.600                0.000   \n",
       "...                    ...                  ...                  ...   \n",
       "10229                0.000               36.500                0.000   \n",
       "10230                0.000               36.700                0.000   \n",
       "10231                0.000               36.700                0.000   \n",
       "10232                0.000               36.100                0.000   \n",
       "10233                0.000               37.100                0.000   \n",
       "\n",
       "                d1_inr_min        h1_sodium_min    immunosuppression  \\\n",
       "0                    1.100              132.000                0.000   \n",
       "1                    2.200              138.000                0.000   \n",
       "2                    2.400              141.000                0.000   \n",
       "3                    1.100              138.000                0.000   \n",
       "4                    1.100              133.000                0.000   \n",
       "...                    ...                  ...                  ...   \n",
       "10229                1.070              138.000                0.000   \n",
       "10230                1.100              138.000                0.000   \n",
       "10231                1.100              138.000                0.000   \n",
       "10232                1.100              138.000                0.000   \n",
       "10233                1.100              138.000                0.000   \n",
       "\n",
       "            d1_albumin_max       d1_calcium_max    h1_hemaglobin_max  \\\n",
       "0                    2.800                9.800               14.500   \n",
       "1                    3.100                8.500               10.900   \n",
       "2                    3.700                9.100               11.800   \n",
       "3                    2.000                9.000               10.900   \n",
       "4                    3.400                8.800               10.700   \n",
       "...                    ...                  ...                  ...   \n",
       "10229                3.100                8.300                9.800   \n",
       "10230                3.100                7.900               10.900   \n",
       "10231                3.100                7.400               10.900   \n",
       "10232                3.100                8.600               10.900   \n",
       "10233                3.100                8.300               10.900   \n",
       "\n",
       "                h1_mbp_min  ...       d1_glucose_min                  age  \\\n",
       "0                   80.000  ...               97.000               72.000   \n",
       "1                   94.000  ...               73.000               86.000   \n",
       "2                  117.000  ...               84.000               72.000   \n",
       "3                   74.000  ...               84.000               66.000   \n",
       "4                   89.000  ...               99.000               89.000   \n",
       "...                    ...  ...                  ...                  ...   \n",
       "10229               96.000  ...               96.000               36.000   \n",
       "10230               74.000  ...               94.000               61.000   \n",
       "10231               73.000  ...              150.000               74.000   \n",
       "10232               89.000  ...               98.000               90.000   \n",
       "10233               88.000  ...               99.000               30.000   \n",
       "\n",
       "            d1_lactate_max                  bmi               icu_id  \\\n",
       "0                    1.000               26.600               82.000   \n",
       "1                    1.000               26.600               82.000   \n",
       "2                    1.000               26.600               82.000   \n",
       "3                    1.000               26.600               82.000   \n",
       "4                    1.000               26.600               82.000   \n",
       "...                    ...                  ...                  ...   \n",
       "10229                1.000               37.500            1,108.000   \n",
       "10230                1.000               32.100            1,108.000   \n",
       "10231                1.000               22.700            1,108.000   \n",
       "10232                1.000               19.900            1,108.000   \n",
       "10233                1.000               25.600            1,108.000   \n",
       "\n",
       "         gcs_verbal_apache     gcs_motor_apache           arf_apache  \\\n",
       "0                    5.000                6.000                0.000   \n",
       "1                    5.000                6.000                0.000   \n",
       "2                    5.000                6.000                0.000   \n",
       "3                    4.000                6.000                0.000   \n",
       "4                    5.000                6.000                0.000   \n",
       "...                    ...                  ...                  ...   \n",
       "10229                5.000                6.000                0.000   \n",
       "10230                5.000                6.000                0.000   \n",
       "10231                5.000                6.000                0.000   \n",
       "10232                4.000                6.000                0.000   \n",
       "10233                1.000                5.000                0.000   \n",
       "\n",
       "         ventilated_apache       d1_glucose_max  \n",
       "0                    0.000              104.000  \n",
       "1                    0.000              102.000  \n",
       "2                    0.000              141.000  \n",
       "3                    1.000               84.000  \n",
       "4                    0.000              159.000  \n",
       "...                    ...                  ...  \n",
       "10229                0.000               96.000  \n",
       "10230                0.000               94.000  \n",
       "10231                0.000              150.000  \n",
       "10232                0.000               98.000  \n",
       "10233                0.000              111.000  \n",
       "\n",
       "[10234 rows x 139 columns]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_HO "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "## change to matrix format\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler().fit(X_HO)\n",
    "X_HO = scaler.transform(X_HO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.08117849, -0.31372148, -0.10083062, ..., -0.14009775,\n",
       "        -0.69960589, -0.80572787],\n",
       "       [-0.08117849,  0.09563262, -0.10083062, ..., -0.14009775,\n",
       "        -0.69960589, -0.83010547],\n",
       "       [-0.08117849, -0.31372148, -0.10083062, ..., -0.14009775,\n",
       "        -0.69960589, -0.3547422 ],\n",
       "       ...,\n",
       "       [-0.08117849,  0.09563262, -0.10083062, ..., -0.14009775,\n",
       "        -0.69960589, -0.24504299],\n",
       "       [-0.08117849, -0.72307557, -0.10083062, ..., -0.14009775,\n",
       "        -0.69960589, -0.87886068],\n",
       "       [-0.08117849,  0.64143808, -0.10083062, ..., -0.14009775,\n",
       "        -0.69960589, -0.72040626]])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_HO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.00625515],\n",
       "       [0.07775888],\n",
       "       [0.03378111],\n",
       "       ...,\n",
       "       [0.04856342],\n",
       "       [0.00307423],\n",
       "       [0.00253177]], dtype=float32)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#predict probabilities on submission hold out data\n",
    "predict_H1 = model.predict(X_HO)\n",
    "predict_H1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "id_col = HO_i['encounter_id'].values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission['encounter_id'] = id_col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission['diabetes_mellitus'] = predict_H1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>encounter_id</th>\n",
       "      <th>diabetes_mellitus</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10229</th>\n",
       "      <td>143750</td>\n",
       "      <td>0.038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10230</th>\n",
       "      <td>143813</td>\n",
       "      <td>0.047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10231</th>\n",
       "      <td>137126</td>\n",
       "      <td>0.049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10232</th>\n",
       "      <td>135652</td>\n",
       "      <td>0.003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10233</th>\n",
       "      <td>136852</td>\n",
       "      <td>0.003</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       encounter_id    diabetes_mellitus\n",
       "10229        143750                0.038\n",
       "10230        143813                0.047\n",
       "10231        137126                0.049\n",
       "10232        135652                0.003\n",
       "10233        136852                0.003"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission= submission.sort_values('encounter_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>encounter_id</th>\n",
       "      <th>diabetes_mellitus</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3723</th>\n",
       "      <td>145996</td>\n",
       "      <td>0.042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9946</th>\n",
       "      <td>145997</td>\n",
       "      <td>0.043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9750</th>\n",
       "      <td>145998</td>\n",
       "      <td>0.028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2117</th>\n",
       "      <td>145999</td>\n",
       "      <td>0.234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7893</th>\n",
       "      <td>146000</td>\n",
       "      <td>0.648</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      encounter_id    diabetes_mellitus\n",
       "3723        145996                0.042\n",
       "9946        145997                0.043\n",
       "9750        145998                0.028\n",
       "2117        145999                0.234\n",
       "7893        146000                0.648"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.to_csv('submission_0226pm_karas.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
